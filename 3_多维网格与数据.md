# 3_多维网格与数据

* [3.1 多维网格组织]()
* [3.2 线程与多维数据的映射]()
* [3.3 图像模糊：更复杂的内核]()
* [3.4 矩阵乘法]()
* [3.5 总结]()
* [练习]()

在第 2 章《异构数据并行计算》中，我们学习了如何编写一个简单的 CUDA C11 程序，该程序通过调用内核函数来操作一维数组的元素，从而启动一维线程网格。内核指定了网格中每个线程执行的语句。在本章中，我们将更一般地探讨线程的组织方式，并学习如何使用线程和块来处理多维数组。本章将通过多个示例进行讲解，包括将彩色图像转换为灰度图像、图像模糊处理和矩阵乘法。这些示例还旨在帮助读者理解数据并行性，然后我们将在接下来的章节中讨论 GPU 架构、内存组织和性能优化。

## 3.1 多维网格组织

在 CUDA 中，网格中的所有线程执行相同的内核函数，它们依靠坐标（即线程索引）来区分彼此，并确定处理数据的适当部分。正如我们在第 2 章《异构数据并行计算》中看到的，这些线程被组织成一个两级层次结构：一个网格由一个或多个块组成，每个块由一个或多个线程组成。块中的所有线程共享相同的块索引，可以通过 `blockIdx`（内置）变量访问。每个线程还有一个线程索引，可以通过 `threadIdx`（内置）变量访问。当线程执行内核函数时，`blockIdx` 和 `threadIdx` 变量的引用会返回线程的坐标。内核调用语句中的执行配置参数指定了网格的维度和每个块的维度。这些维度可以通过 `gridDim` 和 `blockDim`（内置）变量获取。

通常，网格是一个三维（3D）块数组，每个块是一个三维数组的线程。在调用内核时，程序需要指定网格和每个维度中块的大小。这些通过内核调用语句中的执行配置参数（在 <<<...>>> 中）进行指定。第一个执行配置参数指定网格的块维度。第二个参数指定每个块的线程维度。每个这样的参数都有 dim3 类型，它是一个包含三个元素 x、y 和 z 的整数向量类型。这三个元素指定了三个维度的大小。程序员可以通过将未使用维度的大小设置为 1 来使用少于三个维度。

例如，以下主机代码可以用来调用 `vecAddkernel()` 内核函数，并生成一个包含 32 个块的 1D 网格，每个块包含 128 个线程。网格中的线程总数为 128*32=4096：
```cuda
dim3 dimGrid(32, 1, 1);
dim3 dimBlock(128, 1, 1);
vecAddKernel<<<dimGrid,dimBlock>>>(...);
```
请注意，`dimBlock` 和 `dimGrid` 是由程序员定义的主机代码变量。这些变量可以具有任何合法的 C 变量名，只要它们的类型是 dim3。例如，以下语句实现了与上述语句相同的结果：
```cuda
dim3 dog(32, 1, 1);
dim3 cat(128, 1, 1);
vecAddKernel<<<dog, cat>>>(...);
```
网格和块的维度也可以从其他变量计算得出。例如，图 2.12 中的内核调用可以写成如下形式：
```cuda
dim3 dimGrid(ceil(n/256.0), 1, 1);
dim3 dimBlock(256, 1, 1);
vecAddKernel<<<dimGrid,dimBlock>>>(...);
```
这允许块的数量随着向量的大小变化，以便网格中有足够的线程来覆盖所有向量元素。在此示例中，程序员选择将块大小固定为 256。内核调用时变量 n 的值将决定网格的维度。如果 n 等于 1000，网格将由四个块组成。如果 n 等于 4000，网格将有 16 个块。在每种情况下，都有足够的线程来覆盖所有向量元素。一旦网格启动，网格和块的维度将在整个网格执行完成之前保持不变。

为了方便，CUDA 提供了一种特殊的快捷方式来调用具有一维（1D）网格和块的内核。无需使用 dim3 变量，可以使用算术表达式来指定 1D 网格和块的配置。在这种情况下，CUDA 编译器只需将算术表达式作为 x 维度，并假设 y 和 z 维度为 1。这为我们提供了图 2.12 中显示的内核调用语句：
```cuda
vecAddKernel<<<ceil(n/256.0), 256>>>(...);
```
熟悉 C++ 的读者会意识到，这种“简写”约定利用了 C++ 构造函数和默认参数的工作方式。dim3 构造函数的默认参数值为 1。当传递一个单一值时，该值将传递给构造函数的第一个参数，而第二和第三个参数将取默认值 1。结果是一个 1D 网格或块，其中 x 维度的大小是传递的值，而 y 和 z 维度的大小为 1。

在内核函数中，`gridDim` 和 `blockDim` 变量的 x 字段根据执行配置参数的值进行预初始化。例如，如果 n 等于 4000，则在 `vectAddkernel` 内核中对 `gridDim.x` 和 `blockDim.x` 的引用将分别得到 16 和 256。请注意，与主机代码中的 dim3 变量不同，这些变量在内核函数中是 CUDA C 规范的一部分，不能更改。即，`gridDim` 和 `blockDim` 是内核中的内置变量，始终反映网格和块的维度。

在 CUDA C 中，`gridDim.x` 的允许值范围是 1 到 2<sup>31</sup> - 1，`gridDim.y` 和 `gridDim.z` 的允许值范围是 1 到 2<sup>16</sup> - 1（65,535）。块中的所有线程共享相同的 `blockIdx.x`、`blockIdx.y` 和 `blockIdx.z` 值。在块之间，`blockIdx.x` 的值范围是 0 到 `gridDim.x-1`，`blockIdx.y` 的值范围是 0 到 `gridDim.y-1`，`blockIdx.z` 的值范围是 0 到 `gridDim.z-1`。

我们现在转向块的配置。每个块组织成一个 3D 线程数组。通过将 `blockDim.z` 设置为 1，可以创建二维（2D）块。通过将 `blockDim.y` 和 `blockDim.z` 都设置为 1，可以创建一维块，如 `vectorAddkernel` 示例中所示。正如我们之前提到的，网格中的所有块具有相同的维度和大小。块的每个维度中的线程数量由内核调用的第二个执行配置参数指定。在内核中，这个配置参数可以作为 `blockDim` 的 x、y 和 z 字段进行访问。

在当前的 CUDA 系统中，块的总大小限制为 1024 个线程。这些线程可以在三个维度中以任何方式分布，只要线程的总数不超过 1024。例如，`blockDim` 的值 (512, 1, 1)、(8, 16, 4) 和 (32, 16, 2) 都是允许的，但 (32, 32, 2) 不允许，因为线程的总数将超过 1024。

网格及其块不需要具有相同的维度。网格可以具有比块更高的维度，反之亦然。例如，图 3.1 显示了一个小型示例网格，`gridDim` 为 (2, 2, 1)，`blockDim` 为 (4, 2, 2)。这样的网格可以通过以下主机代码创建：
```cuda
dim3 dimGrid(2, 2, 1);
dim3 dimBlock(4, 2, 2);
vecAddKernel<<<dimGrid,dimBlock>>>(...);
```

![image](https://github.com/user-attachments/assets/0f949238-6fc6-4da3-8e08-ed7d07d80b71)
> 图 3.1 CUDA 网格组织的多维示例

图 3.1 中的网格由四个块组成，组织成一个 2*2 的数组。每个块用 (`blockIdx.y`, `blockIdx.x`) 标记。例如，块 (1,0) 的 `blockIdx.y=1` 和 `blockIdx.x=0`。请注意，块和线程标签的排序方式是最高维度优先。这种标记方式的顺序与 C 语句中设置配置参数的顺序相反，

后者是最低维度优先。这种用于标记块的逆序在我们说明线程坐标映射到数据索引以访问多维数据时效果更好。

每个 `threadIdx` 也由三个字段组成：x 坐标 `threadId.x`、y 坐标 `threadIdx.y` 和 z 坐标 `threadIdx.z`。图 3.1 说明了块内线程的组织方式。在此示例中，每个块被组织成 4 * 2 * 2 的线程数组。由于网格中的所有块具有相同的维度，我们仅展示其中一个。图 3.1 展开了块 (1,1) 以显示其 16 个线程。例如，线程 (1,0,2) 的 `threadIdx.z=1`、`threadIdx.y=0` 和 `threadIdx.x=2`。请注意，在此示例中，我们有 4 个块，每个块 16 个线程，总共有 64 个线程在网格中。我们使用这些小数字来保持插图的简单性。典型的 CUDA 网格包含成千上万甚至数百万个线程。


## 3.2 将线程映射到多维数据

选择一维、二维或三维线程组织通常基于数据的性质。例如，图像是一个二维像素数组。使用由二维块组成的二维网格来处理图像中的像素通常很方便。

![image](https://github.com/user-attachments/assets/4dd48257-ef11-4bb3-802d-592707c341e5)
> 图3.2 

图3.2展示了处理一个62×76像素图片P的这种排列方式（垂直方向或y方向有62个像素，水平方向或x方向有76个像素）。假设我们决定使用16×16的块，在x方向和y方向各有16个线程。我们将在y方向需要四个块，在x方向需要五个块，总共需要4×5=20个块，如图3.2所示。粗线标记块的边界。阴影区域描绘了覆盖像素的线程。每个线程被分配处理一个像素，其y和x坐标由其`blockIdx`、`blockDim`和`threadIdx`变量值确定：

```
垂直（行）坐标 = blockIdx.y * blockDim.y + threadIdx.y
水平（列）坐标 = blockIdx.x * blockDim.x + threadIdx.x
```

例如，块(1,0)的线程(0,0)处理的Pin元素可以如下标识：

$$  Pin_{blockIdx.y * blockDim.y + threadIdx.y, blockIdx.x * blockDim.x + threadIdx.x} = Pin_{1 * 16 + 0, 0 * 16 + 0} = Pin_{16, 0} $$

请注意，在图3.2中我们在y方向有两个额外的线程，在x方向有四个额外的线程。也就是说，我们将生成64×80个线程来处理62×76个像素。这类似于图2.9中1D核函数`vecAddKernel`处理1000个元素向量的情况，使用四个256线程块。回想图2.10中的if语句用于防止额外的24个线程生效。同样，我们应该预期图片处理核函数将包含if语句以测试线程的垂直和水平索引是否在像素的有效范围内。

我们假设主机代码使用整数变量n跟踪y方向上的像素数量，另一个整数变量m跟踪x方向上的像素数量。我们进一步假设输入图片数据已复制到设备全局内存中，可以通过指针变量`Pin_d`访问。输出图片已在设备内存中分配，可以通过指针变量`Pout_d`访问。以下主机代码可以用来调用一个二维核函数`colorToGrayscaleConversion`来处理图片，如下所示：

```cuda
dim3 dimGrid(ceil(m/16.0), ceil(n/16.0), 1); 
dim3 dimBlock(16, 16, 1);
colorToGrayscaleConversion<<<dimGrid, dimBlock>>>(Pin_d, Pout_d, m, n);
```

在这个例子中，为简化起见，我们假设块的维度固定为16×16。而网格的维度则取决于图片的维度。要处理一个1500×2000（300万像素）的图片，我们将生成11,750个块：y方向94个块，x方向125个块。在核函数内，引用`gridDim.x`、`gridDim.y`、`blockDim.x`和`blockDim.y`将分别得到125、94、16和16。

在展示核代码之前，我们首先需要了解C语句如何访问动态分配的多维数组的元素。理想情况下，我们希望将`Pin_d`作为二维数组访问，其中行j和列i的元素可以作为`Pin_d[j][i]`访问。然而，根据CUDA C开发的ANSI C标准要求，必须在编译时知道Pin中的列数才能将其作为二维数组访问。不幸的是，对于动态分配的数组，在编译时无法知道这个信息。实际上，使用动态分配的数组的部分原因是允许这些数组的大小和维度根据运行时的数据大小而变化。

因此，动态分配的二维数组的列数信息在编译时设计上是未知的。结果，程序员需要显式地将动态分配的二维数组线性化，或“展平”，为当前的CUDA C中的等效一维数组。

实际上，C中的所有多维数组都是线性化的。这是由于现代计算机中使用“平面”内存空间（参见“内存空间”侧边栏）。对于静态分配的数组，编译器允许程序员使用高维索引语法（例如`Pin_d[j][i]`）来访问其元素。在底层，编译器将它们线性化为等效的一维数组，并将多维索引语法转换为一维偏移。

对于动态分配的数组，当前的CUDA C编译器将这种转换工作留给程序员，因为编译时缺乏维度信息。

> ### 内存空间
> 内存空间是处理器在现代计算机中访问其内存的一种简化视图。内存空间通常与每个运行的应用程序相关联。要由应用程序处理的数据和为应用程序执行的指令存储在其内存空间中的位置。每个位置通常可以容纳一个字节并有一个地址。需要多个字节的变量——浮点数为4个字节，双精度浮点数为8个字节——存储在连续的字节位置。当从内存空间访问数据值时，处理器会给出起始地址（起始字节位置的地址）和所需的字节数。
> 大多数现代计算机至少有4G个字节大小的位置，其中每个G为1,073,741,824（2<sup>30</sup>）。所有位置都有一个从0到最大编号的地址标签。由于每个位置只有一个地址，我们说内存空间具有“平面”组织。结果，所有多维数组最终都被“展平”成等效的一维数组。虽然C程序员可以使用多维数组语法来访问多维数组的元素，但编译器将这些访问转换为指向数组起始元素的基指针以及由这些多维索引计算出的一维偏移。

![image](https://github.com/user-attachments/assets/c8fd7c97-3998-46dc-8a13-ae4791477683)
> 图3.3 C数组的行优先布局。结果是一个等效的一维数组，用索引表达式j*Width+i访问，其中j是行，i是列，一个数组中每行有Width个元素。

有至少两种方法可以线性化二维数组。其一是将同一行的所有元素放入连续位置。然后将行按顺序放入内存空间。这种排列称为行优先布局，如图3.3所示。为了提高可读性，我们用M<sub>j,i</sub>表示第j行第i列的元素M。M<sub>j,i</sub>等效于C表达式M[j][i]，但稍微更易读。图3.3显示了一个4×4矩阵M被线性化为16个元素的一维数组，首先是第0行的所有元素，然后是第1行的四个元素，依此类推。

因此，行j和列i的元素M的等效一维索引为j*4+i。j*4项跳过j行之前的所有元素。i项然后在j行部分中选择正确的元素。例如，M<sub>2,1</sub>的一维索引为2*4+1=9。这在图3.3中有所说明，其中M<sub>9</sub>是M<sub>2,1</sub>的一维等效元素。这就是C编译器线性化二维数组的方式。

另一种线性化二维数组的方法是将同一列的所有元素放入连续位置。然后将列按顺序放入内存空间。这种排列称为列优先布局，由FORTRAN编译器使用。注意二维数组的列优先布局等效于其转置形式的行优先布局。我们不会花更多时间在这个上面，除了提到那些主要先前编程经验是FORTRAN的读者应该意识到CUDA C使用行优先布局而非列优先布局。此外，许多为FORTRAN程序设计的C库使用列优先布局以匹配FORTRAN编译器布局。因此，这些库的手册页通常告诉用户，如果从C程序调用这些库，应转置输入数组。

```cuda
__global__ void colortoGrayscaleConvertion(unsigned char * Pout, unsigned char * Pin, int width, int height) {
    // 计算当前线程对应的列索引
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    // 计算当前线程对应的行索引
    int row = blockIdx.y * blockDim.y + threadIdx.y;

    // 检查线程是否在图像范围内
    if (col < width && row < height) {
        // 计算灰度图像中对应像素的偏移量
        int grayOffset = row * width + col;
        // 计算RGB图像中对应像素的偏移量
        int rgbOffset = grayOffset * CHANNELS;

        // 获取RGB值
        unsigned char r = Pin[rgbOffset];
        unsigned char g = Pin[rgbOffset + 1];
        unsigned char b = Pin[rgbOffset + 2];

        // 将RGB转换为灰度并存储到输出图像
        Pout[grayOffset] = 0.21f * r + 0.71f * g + 0.07f * b;
    }
}
```

我们现在准备研究 `colorToGrayscaleConversion` 的源代码，如图 3.4 所示。内核代码使用以下公式将每个彩色像素转换为其灰度像素：

$$ L = 0.12r + 0.72g + 0.07b $$

在水平方向上共有 `blockDim.x * gridDim.x` 个线程。与 `vecAddKernel` 示例类似，以下表达式生成从 0 到 `blockDim.x * gridDim.x - 1` 的每个整数值（第 06 行）：

```cuda
col = blockIdx.x * blockDim.x + threadIdx.x
```

我们知道 `gridDim.x * blockDim.x` 大于或等于宽度（从主机代码传入的 `m` 值）。我们至少有与水平方向像素数量相同的线程。我们还知道垂直方向的线程数量至少与像素数量相同。因此，只要我们测试并确保只有具有行值和列值在范围内的线程，即 `(col < width) && (row < height)`，我们就可以覆盖图片中的每个像素（第 07 行）。

由于每行有 `width` 个像素，我们可以生成像素在 `row` 行和 `col` 列处的 1D 索引，方法是 `row * width + col`（第 10 行）。这个 1D 索引是 `Pout` 的像素索引，因为输出灰度图像中的每个像素都是 1 字节（无符号字符）。在我们 62*76 的图像示例中，线程 (0,0) 处理的 `Pout` 像素的线性化 1D 索引由以下公式计算：

$$ Pout_{blockIdx.y * blockDim.y + threadIdx.y, blockIdx.x * blockDim.x + threadIdx.x} = Pout_{1 * 16 + 0, 0 * 16 + 0} = Pout_{16, 0} = Pout_{[16 * 76 + 0]} = Pout_{[1216]} $$

至于 `Pin`，我们需要将灰度像素索引乘以 3（第 13 行），因为每个彩色像素存储为三个元素（r、g、b），每个元素都是 1 字节。生成的 `rgbOffset` 给出了 `Pin` 数组中彩色像素的起始位置。我们从 `Pin` 数组的三个连续字节位置读取 r、g 和 b 值（第 14-16 行），计算灰度像素值，并使用 `grayOffset` 将该值写入 `Pout` 数组（第 19 行）。在我们 62*76 的图像示例中，线程 (0,0) 处理的 `Pin` 像素第一个分量的线性化 1D 索引可以通过以下公式计算：

$$ Pin_{blockIdx.y * blockDim.y + threadIdx.y, blockIdx.x + blockDim.x + threadIdx.x} = Pin_{1 * 16 + 0, 0 * 16 + 0} = Pin_{16, 0} = Pin_{[16 * 76 * 3 + 0]} = Pin_{[3648]} $$

![image](https://github.com/user-attachments/assets/5c025a39-b925-4182-afa4-4e600401e053)
> 图 3.5 用 16*16 的块覆盖 76*62 的图片。

访问的数据是从字节偏移量 3648 开始的 3 个字节。图 3.5 说明了 `colorToGrayscaleConversion` 在处理我们 62*76 的示例时的执行情况。假设 16*16 的块，调用 `colorToGrayscaleConversion` 内核生成 64*80 线程。网格将有 4*5=20 个块：垂直方向四个，水平方向五个。块的执行行为将分为四种不同的情况，如图 3.5 中的四个阴影区域所示。

第一个区域，图 3.5 中标记为 1，包括属于覆盖图片大多数像素的 12 个块的线程。这些线程的 `col` 和 `row` 值都在范围内；所有这些线程通过 if 语句测试并处理图片深色阴影区域的像素。即每个块中所有 16*16=256 个线程都将处理像素。

第二个区域，图 3.5 中标记为 2，包含属于中等阴影区域覆盖图片右上像素的三个块的线程。虽然这些线程的行值始终在范围内，但其中一些线程的列值超过了 76 的 m 值。这是因为水平方向上的线程数始终是程序员选择的 `blockDim.x` 值的倍数（在本例中为 16）。覆盖 76 个像素所需的最小 16 的倍数是 80。因此，每行的 12 个线程会发现其列值在范围内并处理像素。其余四个线程将发现其列值超出范围，因此不会通过 if 语句条件。这些线程不会处理任何像素。总体而言，这些块中的 12*16=192 个线程中的 256 个线程将处理像素。

第三个区域，图 3.5 中标记为 3，占据覆盖图片中等阴影区域的左下方四个块。虽然这些线程的列值始终在范围内，但其中一些线程的行值超过了 62 的 n 值。这是因为垂直方向上的线程数始终是程序员选择的 `blockDim.y` 值的倍数（在本例中为 16）。覆盖 62 所需的最小 16 的倍数是 64。因此，每列的 14 个线程会发现其行值在范围内并处理像素。其余两个线程将不会通过 if 语句条件，不会处理任何像素。总体而言，这些块中的 16*14=224 个线程将处理像素。

第四个区域，图 3.5 中标记为 4，包含覆盖图片右下方轻度阴影区域的线程。与区域 2 类似，每列顶部的 4 个线程会发现其列值超出范围。与区域 3 类似，这些块的整个底部两行的线程会发现其行值超出范围。总体而言，只有 14*12=168 个线程中的 256 个线程将处理像素。

我们可以通过在线性化数组时包括另一个维度，将我们的讨论从 2D 数组轻松扩展到 3D 数组。这是通过将数组的每个“平面”一个接一个地放入地址空间来完成的。假设程序员使用变量 `m` 和 `n` 跟踪 3D 数组中列和行的数量。程序员还需要确定在调用内核时 `blockDim.z` 和 `gridDim.z` 的值。在内核中，数组索引将涉及另一个全局索引：

```cuda
int plane = blockIdx.z*blockDim.z + threadIdx.z
```

对 3D 数组 `P` 的线性访问形式为 `P[plane * m * n + row * m + col]`。处理 3D `P` 数组的内核需要检查 `plane`、`row` 和 `col` 的所有三个全局索引是否在数组的有效范围内。在第8章，Stencil 模式中，我们将进一步研究 CUDA 内核中的 3D 数组的使用。

## 3.3 图像模糊：一个更复杂的内核
我们已经研究了 `vecAddkernel` 和 `colorToGrayscaleConversion`，在这些内核中，每个线程只对一个数组元素执行少量的算术操作。
这些内核很好地实现了它们的目的：说明基本的 CUDA C 程序结构和数据并行执行概念。此时，读者应该问一个明显的问题：在 CUDA C 程序中，所有线程是否只独立执行如此简单和琐碎的操作？答案是否定的。在实际的 CUDA C 程序中，线程通常对其数据执行复杂的操作，并需要彼此协作。在接下来的几章中，我们将逐步研究展示这些特征的越来越复杂的例子。
我们将从一个图像模糊函数开始。
图像模糊在保留图像关键特征的边缘的同时，平滑像素值的突然变化。图 3.6 说明了图像模糊的效果。简单地说，我们使图像模糊。
对人眼来说，模糊的图像往往会模糊细节并呈现“大图景”印象，或图片中的主要主题对象。在计算机图像处理算法中，图像模糊的一个常见用例是通过用干净的周围像素值校正有问题的像素值，减少图像中噪声和颗粒渲染效果的影响。在计算机视觉中，图像模糊可以用于允许边缘检测和对象识别算法专注于主题对象，而不是被大量细粒度对象所拖累。在显示器中，图像模糊有时用于通过模糊图像的其他部分来突出图像的特定部分。
从数学上讲，图像模糊函数将输出图像像素的值计算为输入图像中包含该像素的像素块的加权和。正如我们将在第 7 章“卷积”中学习的那样，这种加权和的计算属于卷积模式。在本章中，我们将使用一种简化的方法，通过取围绕目标像素及其周围的 N*N 像素块的简单平均值来模糊图像。为了使算法简单，我们不会根据像素与目标像素的距离对任何像素的值进行加权。在实践中，在卷积模糊方法中进行加权是很常见的，例如高斯模糊。

![image](https://github.com/user-attachments/assets/9ce4ce5b-6aca-4c84-8e58-e18e908d24f4)
> 图 3.6 原始图像（左）和模糊版本（右）。

图 3.7 显示了使用 3*3 像素块的图像模糊示例。在计算输出像素值时，补丁以位于 (row, col) 位置的输入像素为中心。3*3 补丁跨越三行（row-1, row, row+1）和三列（col-1, col, col+1）。例如，用于计算 (25, 50) 位置的输出像素的九个像素的坐标是 (24, 49), (24, 50), (24, 51), (25, 49), (25, 50), (25, 51), (26, 49), (26, 50) 和 (26, 51)。
图 3.8 显示了一个图像模糊内核。与 `colorToGrayscaleConversion` 中使用的策略类似，我们使用每个线程来计算一个输出像素。
即，线程与输出数据的映射保持不变。因此，在内核的开头，我们看到 `col` 和 `row` 索引的熟悉计算（第 03-04 行）。我们还看到熟悉的 if 语句，根据图像的高度和宽度验证 `col` 和 `row` 是否在有效范围内（第 05 行）。只有 `col` 和 `row` 索引都在有效范围内的线程才允许参与执行。

![image](https://github.com/user-attachments/assets/487e3aaa-f082-43b3-ad49-b60e67d0443d)
> 图 3.7 每个输出像素是输入图像中其周围像素和自身的平均值。

如图 3.7 所示，`col` 和 `row` 值还提供了用于计算线程输出像素的输入像素块的中心像素位置。图 3.8 中的嵌套 for 循环（第 10-11 行）遍历补丁中的所有像素。我们假设程序定义了常量 `BLUR_SIZE`。`BLUR_SIZE` 的值设置为补丁每侧的像素数（半径），而 `2*BLUR_SIZE+1` 给出补丁一维的像素总数。例如，对于 3*3 补丁，`BLUR_SIZE` 设置为 1，而对于 7*7 补丁，`BLUR_SIZE` 设置为 3。外循环遍历补丁的行。对于每一行，内循环遍历补丁的列。在我们的 3*3 补丁示例中，`BLUR_SIZE` 为 1。对于计算输出像素 (25, 50) 的线程，在外循环的第一次迭代中，`curRow` 变量为 `row-BLUR_SIZE`=(25-1)=24。因此，在外循环的第一次迭代中，内循环遍历第 24 行的补丁像素。内循环从列 `col-BLUR_SIZE`=50-1=49 到 `col+BLUR_SIZE`=51 使用 `curCol` 变量迭代。因此，在外循环的第一次迭代中处理的像素是 (24, 49), (24, 50) 和 (24, 51)。读者应该验证，在外循环的第二次迭代中，内循环遍历像素 (25, 49), (25, 50) 和 (25, 51)。最后，在外循环的第三次迭代中，内循环遍历像素 (26, 49), (26, 50) 和 (26, 51)。

```cuda
01	__global__
02 	void blurKernel(unsigned char *in, unsigned char *out, int w, int h){
03	    // 计算当前线程处理的像素位置
04	    int col = blockIdx.x * blockDim.x + threadIdx.x;
05	    int row = blockIdx.y * blockDim.y + threadIdx.y;
06 	    // 确保当前线程处理的位置在图像范围内
07 	    if (col < w && row < h) {
08	    	int pixVal = 0;  // 用于累积像素值
09 		    int pixels = 0; // 统计有效像素数量
10		
11		    // 遍历指定大小的模糊区域
12		    for (int blurRow = -BLUR_SIZE; blurRow < BLUR_SIZE + 1; ++blurRow) {
13			    for (int blurCol = -BLUR_SIZE; blurCol < BLUR_SIZE + 1; ++blurCol) {
14				    int curRow = row + blurRow; // 当前处理的行位置
15				    int curCol = col + blurCol; // 当前处理的列位置
16				    // 确保当前处理的位置在图像范围内
17				    if (curRow >= 0 && curRow < h && curCol >= 0 && curCol < w) {
18					    pixVal += in[curRow * w + curCol]; // 累积像素值
19					    ++pixels; // 增加有效像素计数
20				    }
21			    }
22	        }
23	        // 计算平均值并写入输出图像
24	        out[row * w + col] = (unsigned char) (pixVal / pixels);
25	    }
26	}
```
> 图 3.8 图像模糊内核。

使用 `curRow` 和 `curCol` 的线性索引访问当前迭代中访问的输入像素的值。它将像素值累加到一个正在运行的和变量 `pixVal` 中。通过递增 `pixels` 变量记录已累加了一个像素值的事实。
在补丁中的所有像素都被处理后，通过将 `pixVal` 值除以 `pixels` 值来计算补丁中像素的平均值。它使用 `row` 和 `col` 的线性索引将结果写入其输出像素。
包含一个条件语句，保护第 16 和 17 行的执行。例如，在计算图像边缘附近的输出像素时，补丁可能超出输入图像的有效范围。如图 3.9 所示，假设 3*3 补丁。在情况 1 中，左上角的像素正在模糊。预期补丁中的九个像素有五个在输入图像中不存在。在这种情况下，输出像素的 `row` 和 `col` 值分别为 0 和 0。在嵌套循环的执行过程中，九次迭代的 `curRow` 和 `curCol` 值为 (21,21), (21,0), (21,1), (0,21), (0,0), (0,1), (1,21), (1,0), 和 (1,1)。请注意，对于图像外部的五个像素，至少一个值小于 0。if 语句的 `curRow`，0 和 `curCol`，0 条件捕获这些值并跳过第 16 和 17 行的执行。
因此，只有四个有效像素的值被累加到运行和变量中。像素值也只正确递增四次，以便在第 22 行正确计算平均值。

![image](https://github.com/user-attachments/assets/f6ab5bc5-fb73-4f86-8729-9f0f27715fcf)
> 图 3.9

读者应该研究图 3.9 中的其他情况，并分析 `blurKernel` 中嵌套循环的执行行为。请注意，大多数线程会发现其分配的 3*3 补丁中的所有像素都在输入图像中。它们将累加所有九个像素。然而，对于四个角上的像素，负责的线程将只累加四个像素。对于四个边上的其他像素，负责的线程将累加六个像素。这些变化是跟踪实际累加的像素数的必要原因。

## 3.4 矩阵乘法

矩阵乘法（或简称为矩阵乘法）是基础线性代数子程序（BLAS）标准的重要组成部分（参见“线性代数函数”侧栏）。它是许多线性代数求解器的基础，例如 LU 分解。它也是深度学习中使用卷积神经网络的重要计算，在第 16 章“深度学习”中将详细讨论。

> ### 线性代数函数
> 线性代数操作广泛应用于科学和工程应用中。在基础线性代数子程序（BLAS）中，有三层线性代数函数。随着层次的增加，函数执行的操作数量也增加。第 1 层函数执行形式为 y=αx+y 的向量操作，其中 x 和 y 是向量，α 是标量。我们的向量加法示例是 α=1 时第 1 层函数的特例。第 2 层函数执行形式为 y=αAx+βy 的矩阵向量操作，其中 A 是矩阵，x 和 y 是向量，α 和 β 是标量。我们将在稀疏线性代数中研究一种第 2 层函数。第 3 层函数执行形式为 C=αAB+βC 的矩阵矩阵操作，其中 A、B 和 C 是矩阵，α 和 β 是标量。我们的矩阵乘法示例是 α=1 和 β=0 时第 3 层函数的特例。这些 BLAS 函数很重要，因为它们被用作高层代数函数（如线性系统求解器和特征值分析）的基本构建块。正如我们将要讨论的，不同 BLAS 函数实现的性能在顺序和并行计算机中可能相差几个数量级。

一个 I*j（i 行 j 列）矩阵 M 和一个 j*k 矩阵 N 的矩阵乘法生成一个 I*k 矩阵 P。当执行矩阵乘法时，输出矩阵 P 的每个元素是 M 的一行和 N 的一列的内积。我们将继续使用 P<sub>row,col</sub> 表示 P 中第 row 行第 col 列的元素。如图 3.10 所示，P<sub>row,col</sub>（P 中的小方块）是 M 的第 row 行（M 中的水平条）和 N 的第 col 列（N 中的垂直条）组成的向量的内积。两个向量的内积有时称为点积，是各个向量元素乘积的和。即：

$$ P_{row,col} = \sum M_{row,k} * N_{k,col} \text{ for } k=0, 1, . . .Width-1 $$

例如，在图 3.10 中，假设 row=1 和 col=5，

$$ P_{1,5} = M_{1,0} * N_{0,5} + M_{1,1} * N_{1,5} + M_{1,2} * N_{2,5} + ... + M_{1,Width-1} * N_{Width-1,5} $$

![image](https://github.com/user-attachments/assets/447f29e3-cc48-4387-b57f-3d68abd28eda)
> 图 3.10 通过平铺 P 使用多个块进行矩阵乘法。

要使用 CUDA 实现矩阵乘法，我们可以将网格中的线程映射到输出矩阵 P 的元素，与我们在 `colorToGrayscaleConversion` 中使用的方法相同。即，每个线程负责计算一个 P 元素。每个线程计算的 P 元素的行和列索引与之前相同：

```cuda
row = blockIdx.y * blockDim.y + threadIdx.y
```

和

```cuda
col = blockIdx.x * blockDim.x + threadIdx.x
```

```cuda
__global__ void MatrixMulKernel(float* M, float* N, float* P, int Width){
     int row = blockIdx.y * blockDim.y + threadIdx.y;
     int col = blockIdx.x * blockDim.x + threadIdx.x;
     if ((row < Width) && (col < Width)){
          float Pvalue = 0;
          for (int k = 0; k < Width; ++k){
              Pvalue += M[row * Width + k] * N[k * Width + col];
          }
          P[row * Width + col] = Pvalue;
     }
}
```

> 图 3.11 使用一个线程计算一个 P 元素的矩阵乘法核函数。

通过这种一对一的映射，`row` 和 `col` 线程索引也是其输出元素的行和列索引。图 3.11 显示了基于这种线程到数据映射的核函数的源代码。读者应立即看到计算 `row` 和 `col`（第 03-04 行）以及 if 语句测试 `row` 和 `col` 是否都在范围内（第 05 行）的熟悉模式。这些语句几乎与 `colorToGrayscaleConversion` 中的对应语句相同。唯一显著的区别是我们简化了 `matrixMulKernel` 只处理方矩阵，因此用 `Width` 替换了宽度和高度。这种线程到数据的映射有效地将 P 分成了一个个小块，如图 3.10 中的浅色方块。每个块负责计算其中一个小块。

我们现在将注意力转向每个线程完成的工作。回想一下，P<sub>row,col</sub> 是 M 的第 row 行和 N 的第 col 列的内积。在图 3.11 中，我们使用一个 for 循环来执行这个内积操作。进入循环之前，我们将一个局部变量 `Pvalue` 初始化为 0（第 06 行）。循环的每次迭代访问 M 的第 row 行中的一个元素和 N 的第 col 列中的一个元素，将两个元素相乘，并将乘积累加到 `Pvalue` 中（第 08 行）。首先让我们关注循环内的 M 元素访问。M 按行优先顺序线性化为等效的 1D 数组。即，M 的行一个接一个地放置在内存空间中，从第 0 行开始。因此，第 1 行的开始元素是 `M[1 * Width]`，因为我们需要考虑第 0 行的所有元素。一般来说，第 row 行的开始元素是 `M[row * Width]`。由于行中的所有元素都连续放置，row 行的第 k 个元素在 `M[row * Width + k]`。这是我们在图 3.11 中使用的线性化数组偏移量（第 08 行）。

现在我们转向 N 的访问。如图 3.11 所示，col 列的开始元素是第 0 行的第 col 个元素，即 `N[col]`。访问 col 列的下一个元素需要跳过一整行。这是因为同一列的下一个元素是下一行中的相同元素。因此，col 列的第 k 个元素在 `N[k * Width + col]`（第 08 行）。退出 for 循环后，所有线程都有它们的 P 元素值存储在 `Pvalue` 变量中。然后每个线程使用等效的 1D 索引表达式 `row * Width + col` 写入其 P 元素（第 10 行）。这种索引模式与 `colorToGrayscaleConversion` 核函数中使用的类似。

![image](https://github.com/user-attachments/assets/6fbde23c-5e4f-4d62-ad43-87124edd2ef1)
> 图 3.12 `matrixMulKernel` 的一个小执行示例。

现在我们使用一个小示例来说明矩阵乘法核函数的执行。图 3.12 显示了一个 4x4 的 P，`BLOCK_WIDTH`=2。虽然这种小矩阵和块大小不太现实，但它们允许我们将整个示例放入一张图片中。P 矩阵被分成了四个小块，每个块计算一个小块。我们通过创建 2x2 线程数组的块来实现这一点，每个线程计算一个 P 元素。在示例中，块 (0,0) 的线程 (0,0) 计算 P<sub>0,0</sub>，而块 (1,0) 的线程 (0,0) 计算 P<sub>2,0</sub>。`matrixMulKernel` 中的行和列索引标识线程要计算的 P 元素。行索引还标识 M 的行，列索引标识 N 的列，作为线程的输入值。图 3.13 说明了每个线程块中的乘法操作。对于这个小矩阵乘法示例，块 (0,0) 中的线程生成四个点积。块 (0,0) 中线程 (1,0) 的行和列索引分别为 0 * 0 + 1 = 1 和 0 * 0 + 0 = 0。因此该线程映射到 P<sub>1,0</sub> 并计算 M 的第 1 行和 N 的第 0 列的点积。让我们逐步执行图 3.

11 中块 (0,0) 中线程 (0,0) 的 for 循环。第 0 次迭代（k=0）时，`row * Width + k`=0 * 4 + 0 = 0 和 `k * Width + col`=0 * 4 + 0 = 0。因此访问的输入元素是 `M[0]` 和 `N[0]`，它们是 M<sub>0,0</sub> 和 N<sub>0,0</sub> 的 1D 等效元素。注意这些确实是 M 第 0 行和 N 第 0 列的第 0 个元素。第 1 次迭代（k=1）时，`row * Width + k`=0 * 4 + 1 = 1 和 `k * Width + col`=1 * 4 + 0 = 4。因此我们访问 `M[1]` 和 `N[4]`，它们是 M<sub>0,1</sub> 和 N<sub>1,0</sub> 的 1D 等效元素。这些是 M 第 0 行和 N 第 0 列的第一个元素。第 2 次迭代（k=2）时，`row * Width + k`=0 * 4 + 2 = 2 和 `k * Width + col`=2 * 4 + 0 = 8，这导致访问 `M[2]` 和 `N[8]`。因此访问的元素是 M<sub>0,2</sub> 和 N<sub>2,0</sub> 的 1D 等效元素。最后，第 3 次迭代（k=3）时，`row * Width + k`=0 * 4 + 3 = 3 和 `k * Width + col`=3 * 4 + 0 = 12，这导致访问 `M[3]` 和 `N[12]`，它们是 M<sub>0,3</sub> 和 N<sub>3,0</sub> 的 1D 等效元素。我们现在验证 for 循环确实对块 (0,0) 中线程 (0,0) 的 M 第 0 行和 N 第 0 列执行了内积。循环后，线程写入 `P[row * Width + col]`，即 `P[0]`。这是 P<sub>0,0</sub> 的 1D 等效元素，因此块 (0,0) 中线程 (0,0) 成功计算了 M 第 0 行和 N 第 0 列的内积，并将结果存入 P<sub>0,0</sub>。我们将其作为练习，读者可以手动执行并验证块 (0,0) 中其他线程或其他块的 for 循环。

由于网格大小受限于每个网格的最大块数和每个块的最大线程数，`matrixMulKernel` 能处理的最大输出矩阵 P 的大小也将受这些限制的约束。在需要计算大于此限制的输出矩阵的情况下，可以将输出矩阵划分为网格可以覆盖的子矩阵，并使用主机代码为每个子矩阵启动不同的网格。或者，我们可以更改核代码，使每个线程计算更多的 P 元素。我们将在本书后面探讨这两种选项。

## 3.5 总结

CUDA 网格和块是多维的，最多可以有三个维度。网格和块的多维性对于将线程组织成多维数据非常有用。内核执行配置参数定义了网格及其块的维度。`blockIdx` 和 `threadIdx` 中的唯一坐标允许网格中的线程标识自己及其数据域。程序员的责任是使用这些变量在内核函数中，使线程能够正确标识要处理的数据部分。

![image](https://github.com/user-attachments/assets/5d90468c-e9fc-470e-a280-20fcd2d96ef1)
> 图 3.13 一个线程块的矩阵乘法操作。

访问多维数据时，程序员通常需要将多维索引线性化为 1D 偏移量。原因是 C 中动态分配的多维数组通常按行优先顺序存储为 1D 数组。我们通过复杂度逐渐增加的示例，让读者熟悉使用多维网格处理多维数组的机制。这些技能将是理解并行模式及其相关优化技术的基础。
