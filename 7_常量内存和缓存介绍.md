# 7_常量内存和缓存介绍

* [7.1 背景] 
* [7.2 并行卷积：基本算法] 
* [7.3 常量内存和缓存] 
* [7.4 带有边界单元的块状卷积] 
* [7.5 使用缓存的带有边界单元的块状卷积] 
* [7.6 总结] 
* [练习] 

在接下来的几章中，我们将讨论一组重要的并行计算模式。这些模式是广泛并行算法的基础，这些算法出现在许多并行应用中。我们将从卷积开始，这是一个流行的数组操作，在信号处理、数字录音、图像处理、视频处理和计算机视觉中以多种形式使用。在这些应用领域中，卷积通常作为一种滤波器来变换信号和像素，使其变得更加理想。我们的图像模糊内核就是这样一个滤波器，用于平滑信号值，以便可以看到整体趋势。例如，高斯滤波器是一种卷积滤波器，可以用来锐化图像中物体的边界和边缘。

卷积通常执行大量的算术操作以生成每个输出元素。对于像高清图像和视频这样的大数据集，其中有许多输出元素（像素），计算量可能非常庞大。一方面，卷积的每个输出数据元素可以相互独立计算，这是并行计算的一个理想特征。另一方面，在处理不同的输出数据元素时，存在大量的输入数据共享，以及具有一定挑战性的边界条件。这使得卷积成为复杂块状方法和输入数据分阶段处理方法的重要用例，这些方法是本章的重点。

## 7.1 背景

卷积是一种数组操作，其中每个输出数据元素是对应输入元素和一组以其为中心的输入元素的加权和。加权和计算中使用的权重由一个滤波器数组定义，通常称为卷积核。由于CUDA内核函数和卷积核之间有一个不幸的名称冲突，我们将这些滤波器数组称为卷积滤波器，以避免混淆。

卷积可以在不同维度的输入数据上执行：一维（1D）（例如，音频）、二维（2D）（例如，照片）、三维（3D）（例如，视频）等。在音频数字信号处理领域，输入的一维数组元素是随时间采样的信号音量。也就是说，输入数据元素 x<sub>i</sub> 是音频信号音量的第 i 个样本。1D 数据上的卷积，称为 1D 卷积，在数学上定义为一个函数，该函数接受一个包含 n 个元素的输入数据数组 [x<sub>0</sub>, x<sub>1</sub>, ..., x<sub>n-1</sub>] 和一个包含 2r + 1 个元素的滤波器数组 [f<sub>0</sub>, f<sub>1</sub>, ..., f<sub>2r</sub>]，并返回一个输出数据数组 y：

$$ y_{i} = \sum^{r}_{j=-r} f_{j} * x_{i+j} $$

由于滤波器的大小是一个奇数（2r+1），加权和计算在被计算的元素周围是对称的。也就是说，加权和涉及到计算位置两侧的 r 个输入元素，这就是为什么 r 被称为滤波器的半径的原因。

图 7.1 显示了一个 1D 卷积示例，其中一个五元素（r = 2）的卷积滤波器 f 应用于一个七元素的输入数组 x。我们将遵循 C 语言的约定，其中 x 和 y 元素的索引从 0 到 6，f 元素的索引从 0 到 4。由于滤波器半径为 2，每个输出元素是相应输入元素的加权和，左侧两个元素和右侧两个元素的加权和。

![image](https://github.com/user-attachments/assets/061b93f4-3334-4f7d-af39-2a48e5db3e6c)
> 图 7.1 1D 卷积示例，内部元素。

例如，y[2] 的值是 x[0]（即 x[2 - 2]）到 x[4]（即 x[2 + 2]）的加权和。在这个示例中，我们随意假设 x 元素的值为 [8, 2, 5, 4, 1, 7, 3]。f 元素定义了权重，在这个示例中其值为 1、3、5、3、1。每个 f 元素都乘以相应的 x 元素值，然后将这些乘积相加。如图 7.1 所示，y[2] 的计算如下：

$$ y[2] = f[0]*x[0] + f[1]*x[1] + f[2]*x[2] + f[3]*x[3] + f[4]*x[4] = 1*8 + 3*2 + 5*5 + 3*4 + 1*1 = 52 $$

在图 7.1 中，y[i] 的计算可以看作是 x 子数组（从 x[i - 2] 开始）和 f 数组之间的内积。图 7.2 显示了 y[3] 的计算。该计算比图 7.1 中的计算向右移动了一个 x 元素。也就是说，y[3] 的值是 x[1]（即 x[3 - 2]）到 x[5]（即 x[3 + 2]）的加权和。我们可以将 x[3] 的计算视为如下内积：

$$ y[3] = f[0]*x[1] + f[1]*x[2] + f[2]*x[3] + f[3]*x[4] + f[4]*x[5] = 1*2 + 3*5 + 5*4 + 3*1 + 1*7 = 47 $$

由于卷积是在相邻元素之间定义的，因此在计算接近数组边缘的输出元素时自然会出现边界条件。如图 7.3 所示，当我们计算 y[1] 时，x[1] 左侧只有一个 x 元素。也就是说，根据我们的卷积定义，没有足够的 x 元素来计算 y[1]。处理这种边界条件的典型方法是为这些缺失的 x 元素分配一个默认值。对于大多数应用，默认值是 0，这也是图 7.3 中使用的默认值。例如，在音频信号处理中，我们可以假设录音开始前和结束后信号音量为 0。在这种情况下，y[1] 的计算如下：

$$ y[1] = f[0]*0 + f[1]*x[0] + f[2]*x[1] + f[3]*x[2] + f[4]*x[3] = 1*0 + 3*8 + 5*2 + 3*5 + 1*4 = 53 $$

![image](https://github.com/user-attachments/assets/2b1aa480-be96-4ed6-8de5-be432cc9fc35)
> 图 7.2 1D 卷积，y[3] 的计算。

图 7.3 中缺失的 x 元素用虚线框表示。显然，y[0] 的计算将涉及两个缺失的 x 元素，在这个示例中，它们都将假设为 0。我们将 y[0] 的计算留作练习。这些缺失的元素在文献中通常被称为虚拟单元。由于在并行计算中使用了块状处理，也存在其他类型的虚拟单元。这些虚拟单元可能对块状处理的有效性和/或效率产生重大影响。我们将很快回到这一点。

![image](https://github.com/user-attachments/assets/fb862803-bc22-46e8-be90-c9b7f44b1af5)
> 图 7.3 1D 卷积边界条件。

此外，并非所有应用程序都假设虚拟单元包含 0。例如，一些应用程序可能假设虚拟单元包含与边缘上最近有效数据元素相同的值。

对于图像处理和计算机视觉，输入数据通常表示为二维数组，其中像素位于 x 和 y 空间中。因此，图像卷积是二维卷积，如图 7.4 所示。在二维卷积中，滤波器 f 也是一个二维数组。它的 x 和 y 维度确定了加权和计算中要包含的邻居范围。如果我们假设滤波器在 x 维度的大小为 (2r<sub>x</sub> + 1)，在 y 维度的大小为 (2r<sub>y</sub> + 1)，则每个 P 元素的计算可以表示为：

$$ P_{y,x} = \sum^{r_{y}}_{j=-r_{y}} \sum^{r_{x}}_{k=-r_{x}} f_{y+j,x+k} * N_{y,x} $$

![image](https://github.com/user-attachments/assets/35fbfad8-d316-4544-b4b6-5376cfafafe3)
> 图 7.4 2D 卷积示例。

图 7.4 中我们使用了一个 5 × 5 的滤波器；即 r<sub>y</sub> = 2 和 r<sub>x</sub> = 2。通常，滤波器不一定是正方形数组，但通常是正方形数组。为了生成输出元素，我们取一个子数组，其中心位于输入数组 N 中的相应位置。然后对滤波器数组和图像数组的元素进行成对乘法。对于我们的示例，结果显示为图 7.4 中 N 和 P 下方的 5 × 5 乘积数组。输出元素的值是所有乘积数组元素的总和。

图 7.4 中的示例显示了 P2,2 的计算。为了简洁起见，我们将使用 N<sub>y,x</sub> 来表示 C 数组中的 N[y][x]。由于 N 和 P 很可能是动态分配的数组，我们将在实际代码示例中使用线性化的索引。计算如下：

![image](https://github.com/user-attachments/assets/d24d3677-c3c6-422d-bd60-a3d3a6cac17e)

与 1D 卷积一样，2D 卷积也必须处理边界条件。在 x 和 y 维度的边界下，边界条件变得更加复杂：输出元素的计算可能涉及水平边界、垂直边界或两者的边界条件。图 7.5 说明了涉及两个边界的 P 元素的计算。从图 7.5 可以看出，P1,0 的计算涉及 N 的子数组中的两列缺失和一行缺失。与 1D 卷积一样，不同的应用程序对这些缺失的 N 元素假设不同的默认值。在我们的示例中，我们假设默认值为 0。这些边界条件也会影响块状处理的效率。我们将很快回到这一点。

![image](https://github.com/user-attachments/assets/fc6a882f-f745-4e91-951e-afa3942f5e6e)
> 图 7.5 2D 卷积的边界条件。

## 7.2 并行卷积：基础算法

由于卷积中所有输出元素的计算都可以并行进行，因此卷积是并行计算的理想用例。根据我们在矩阵乘法中的经验，我们可以快速编写一个简单的并行卷积内核。我们将展示 2D 卷积的代码示例，读者可以将这些代码示例应用于 1D 和 3D 作为练习。此外，为了简化起见，我们假设滤波器是正方形的。

第一步是定义内核的主要输入参数。我们假设 2D 卷积内核接收五个参数：输入数组 N 的指针；滤波器 F 的指针；输出数组 P 的指针；正方形滤波器的半径 r；输入和输出数组的宽度 width；以及输入和输出数组的高度 height。我们有如下设置：

```cuda
__global__ void convolution_2D_basic_kernel(float *N, float *F, float *P, int r, int width, int height){
    //内核主体
}
```

第二步是确定和实现线程到输出元素的映射。由于输出数组是 2D 的，一种简单而有效的方法是将线程组织成一个 2D 网格，让网格中的每个线程计算一个输出元素。每个块最多可以有 1024 个线程，因此可以计算多达 1024 个输出元素。图 7.6 显示了一个玩具示例，其中输入和输出是 16 × 16 的图像。在这个示例中，我们假设每个线程块被组织成一个 4 × 4 的线程数组：x 维度四个线程，y 维度四个线程。网格在这个示例中被组织成一个 4 × 4 的块数组。线程到输出元素的分配——在这个示例中是输出像素——很简单：每个线程被分配到计算一个输出像素，其 x 和 y 索引与线程的 x 和 y 索引相同。

读者应该注意到，图 7.6 中的并行化安排与第 3 章中的 `ColorToGrayScaleConversion` 示例相同，因此我们可以使用图 7.7 中内核的第 02 和第 03 行的语句，从块索引、块维度和线程索引计算输出元素的索引。例如，块<sub>1, 1</sub> 的线程<sub>1, 1</sub> 映射到输出元素 P[1*4+1][1*4+1]=P[5][5]，在图 7.6 中标记为绿色方块。

![image](https://github.com/user-attachments/assets/e82ae09b-02a0-4f63-94c8-56f38b380232)
> 图 7.6 2D 卷积的并行化和线程组织。

一旦确定了每个线程的输出元素索引，我们就可以识别计算输出元素所需的输入 N 元素。如图 7.6 所示，由线程<sub>1, 1</sub> 的块<sub>1, 1</sub> 计算的 P[5][5]（绿色方块）将使用 x 索引范围从 `outCol - r=3` 到 `outCol + r=7`，y 索引范围从 `outRow - r=3` 到 `outRow + r=7` 的输入元素。对于所有线程，`outCol - r` 和 `outRow - r` 定义了所需输入元素的补丁的左上角（重阴影方块），因此我们可以使用双重嵌套循环遍历所有这些索引值并执行计算（图 7.7 的第 05-13 行）。

寄存器变量 `Pvalue` 将累积所有中间结果，以节省 DRAM 带宽。内层 for 循环中的 if 语句测试是否任何用于计算的输入 N 元素是 N 数组的左侧、右侧、顶部或底部的虚拟单元。由于我们假设虚拟单元将使用 0 值，我们可以简单地跳过虚拟单元元素及其相应的滤波器元素的乘法和累积。在循环结束后，我们将 `Pvalue` 释放到输出 P 元素中（第 14 行）。

我们对图 7.7 中的内核有两个观察。首先，将会有控制流分歧。计算 P 数组四个边缘附近输出元素的线程将需要处理虚拟单元。如第 7.1 节所示，每个线程将遇到不同数量的虚拟单元。因此它们在 if 语句（第 09 行）中会有不同的决策。计算 P[0][0] 的线程大部分时间将跳过乘法-累积语句，而计算 P[0][1] 的线程将跳过较少的次数，依此类推。控制分歧的成本将取决于输入数组的宽度和高度以及滤波器的半径。对于大型输入数组和小滤波器，控制分歧只会出现在计算小部分输出元素时，这将使控制分歧的影响保持较小。由于卷积通常应用于大图像，我们预计控制分歧的影响从适中到微不足道。

```cuda
__global__ void convolution_2D_basic_kernel(float *N, float *F, float *P, int r, int width, int height){
    int outCol = blockIdx.x*blockDim.x + threadIdx.x;
    int outRow = blockIdx.y*blockDim.y + threadIdx.y;
    float Pvalue = 0.0f;
    for(int fRow = 0; fRow < 2*r+1; fRow++){
        for(int fCol = 0; fCol < 2*r+1; fCol++){
            int inRow = outRow - r + fRow;
            int inCol = outCol - r + fCol;
            if(inRow >= 0 && inRow < height && inCol >= 0 && inCol < width){
                Pvalue += F[fRow*width + fCol]*N[inRow*width + inCol];
            }
        }
    }
    P[outRow*width + outCol] = Pvalue;
}
```
> 图 7.7 处理边界条件的 2D 卷积内核。

一个更严重的问题是内存带宽。浮点运算与全局内存访问的比率只有大约 0.25 OP/B（每加载 8 字节执行 2 次操作）。正如我们在矩阵乘法示例中看到的，这个简单的内核预计只能以极低的峰值性能运行。我们将在接下来的两节中讨论减少全局内存访问的两个关键技术。

## 7.3 常量内存和缓存

在卷积中，滤波器数组 F 的使用有三个有趣的属性。首先，F 的大小通常很小；大多数卷积滤波器的半径为 7 或更小。即使在 3D 卷积中，滤波器通常也只包含不超过 7<sup>3</sup> = 343 个元素。第二，F 的内容在卷积内核的执行过程中不会改变。第三，所有线程都访问滤波器元素。更好的是，所有线程以相同的顺序访问 F 元素，从 F[0][0] 开始，通过图 7.7 中的双重嵌套 for 循环逐个元素进行访问。这三个属性使得滤波器非常适合使用常量内存和缓存（图 7.8）。

![image](https://github.com/user-attachments/assets/92b22fe3-630e-440e-ab3c-44552c6369af)
> 图 7.8 CUDA 内存模型的概述。

如第 5 章“内存架构和数据局部性”（表 5.1）所讨论的，CUDA C 允许程序员声明变量驻留在常量内存中。与全局内存变量类似，常量内存变量对所有线程块都是可见的。主要区别在于，常量内存变量的值在内核执行期间不能被线程修改。此外，常量内存的大小相当小，目前为 64 KB。

要使用常量内存，主机代码需要以与全局内存变量不同的方式分配和复制常量内存变量。我们假设滤波器的半径在编译时常量 `FILTER_RADIUS` 中指定。要在常量内存中声明一个 F 数组，主机代码将其声明为全局变量，如下所示：

```cuda
#define FILTER_RADIUS 2
__constant__ float F[2*FILTER_RADIUS+1][2*FILTER_RADIUS+1];
```

请注意，这是一个全局变量声明，应该在源文件中的任何函数之外。关键字 `__constant__`（两侧各两个下划线）告诉编译器数组 F 应放置在设备常量内存中。

假设主机代码已经在主机内存中分配和初始化了一个名为 `F_h` 的滤波器掩码数组，包含 (`2*FILTER_RADIUS+1)^2` 个元素。`F_h` 的内容可以通过以下方式从主机内存传输到设备常量内存中的 F：

```cuda
cudaMemcpyToSymbol(F,F_h,(2*FILTER_RADIUS+1)*(2*FILTER_RADIUS+1)*sizeof(float));
```

请注意，这是一个特殊的内存复制函数，它通知 CUDA 运行时在内核执行期间数据将不会被修改。通常，`cudaMemcpyToSymbol()` 函数的使用方式如下：

```cuda
cudaMemcpyToSymbol(dest, src, size);
```

其中 `dest` 是指向常量内存中的目标位置的指针，`src` 是指向主机内存中源数据的指针，`size` 是要复制的字节数。

内核函数访问常量内存变量的方式类似于访问全局变量。因此，它们的指针不需要作为参数传递给内核。我们可以修订内核以使用常量内存，如图 7.9 所示。请注意，内核看起来几乎与图 7.7 中的内核相同。唯一的区别是 F 不再通过传入的指针访问，而是作为全局变量访问。请记住，所有 C 语言的全局变量作用域规则在这里适用。如果主机代码和内核代码在不同的文件中，内核代码文件必须包含相关的外部声明信息，以确保 F 的声明对内核可见。

```cuda
__global__ void convolution_2D_const_mem_kernel(float *N, float *P, int r, int width, int height){
    int outCol = blockIdx.x*blockDim.x + threadIdx.x;
    int outRow = blockIdx.y*blockDim.y + threadIdx.y;
    float Pvalue = 0.0f;
    for(int fRow = 0; fRow < 2*r+1; fRow++){
        for(int fCol = 0; fCol < 2*r+1; fCol++){
            int inRow = outRow - r + fRow;
            int inCol = outCol - r + fCol;
            if(inRow >= 0 && inRow < height && inCol >= 0 && inCol < width){
                Pvalue += F[fRow][fCol]*N[inRow*width + inCol];
            }
        }
    }
    P[outRow*width+outCol] = Pvalue;
}
```
> 图 7.9 使用常量内存的 2D 卷积内核。

与全局内存变量一样，常量内存变量也位于 DRAM 中。然而，由于 CUDA 运行时知道常量内存变量在内核执行期间不会被修改，它会指示硬件在内核执行期间积极缓存常量内存变量。为了理解使用常量内存的好处，我们需要首先了解现代处理器内存和缓存层次结构的更多信息。

如第 6 章“性能考虑”所讨论的，DRAM 的长延迟和有限带宽在几乎所有现代处理器中都形成了瓶颈。为了缓解这种内存瓶颈的影响，现代处理器通常使用片上缓存或缓存来减少需要从主内存（DRAM）中访问的变量数量，如图 7.10 所示。

与 CUDA 共享内存或一般的临时存储器不同，缓存对程序是“透明”的。也就是说，要使用 CUDA 共享内存来保存全局变量的值，程序需要将变量声明为 `__shared__` 并显式地将全局内存变量的值复制到共享内存变量中。另一方面，在使用缓存时，程序只需访问原始全局内存变量。处理器硬件会自动保留最近或最常用的变量在缓存中，并记住它们原始的全局内存地址。当一个保留的变量稍后被使用时，硬件将从其地址检测到变量的副本存在于缓存中。然后，变量的值将从缓存中提供，消除了访问 DRAM 的需要。

内存大小和速度之间存在权衡。因此，现代处理器通常采用多个级别的缓存。这些缓存级别的编号约定反映了与处理器的距离。最低级别的缓存，即 L1 缓存，直接附加到处理器核心，如图 7.10 所示。它在延迟和带宽上都接近处理器的速度。然而，L1 缓存较小，通常在 16 到 64 KB 之间。L2 缓存较大，容量范围从几百千字节到少量 MB，但访问可能需要几十个周期。它们通常在多个处理器核心或 CUDA 设备中的流式多处理器（SMs）之间共享，因此访问带宽在 SMs 之间共享。在一些高端处理器中，还有 L3 缓存，其容量可达数百兆字节。

![image](https://github.com/user-attachments/assets/1492ff05-17ec-4d7d-a029-ff6c416c87f9)
> 图 7.10 现代处理器缓存层次结构的简化视图。

常量内存变量在设计和使用大规模并行处理器中的内存时扮演了一个有趣的角色。由于这些常量内存变量在内核执行期间不会被修改，因此在 SM 中缓存它们时不需要支持线程的写入。支持高吞吐量写入到通用缓存需要复杂的硬件逻辑，并且在芯片面积和功耗方面是昂贵的。由于不需要支持写入，因此可以以高效的方式设计专用缓存，节省芯片面积和功耗。此外，由于常量内存相当小（64 KB），一个小的专用缓存可以非常有效地捕获每个内核重度使用的常量内存变量。这种专用缓存称为现代 GPU 中的常量缓存。因此，当 warp 中的所有线程访问相同的常量内存变量时，如图 7.9 中的 F，其中访问 F 的索引独立于线程索引，常量缓存可以提供大量带宽以满足这些线程的数据需求。此外，由于 F 的大小通常很小，我们可以假设所有 F 元素都可以有效地从常量缓存中访问。

因此，我们可以简单地假设没有 DRAM 带宽用于访问 F 元素。通过使用常量内存和缓存，我们有效地将浮点运算与内存访问的比率提高到约 0.5 OP/B（每 4 字节加载 2 次操作）。

实际上，输入 N 数组元素的访问也可以受益于缓存。我们将在第 7.5 节中回到这一点。

## 7.4 使用边界单元的平铺卷积

我们可以通过平铺卷积算法来解决卷积中的内存带宽瓶颈。回顾一下，在平铺算法中，线程协作将输入元素加载到片上内存中，以便后续使用这些元素。我们首先需要确定输入和输出平铺的定义，因为这些定义对于理解算法的设计很重要。我们将处理每个块的输出元素的集合称为输出平铺。回忆一下，图7.6展示了一个使用16个16线程块的16×16二维卷积的玩具示例。在这个示例中，有16个输出平铺。请记住，我们使用每个块16个线程是为了使示例更小。在实际应用中，每个块应该至少有32个线程，即一个warp，通常还会有更多，以实现良好的占用率和数据重用。从现在开始，我们将假设F元素在常量内存中。

我们定义输入平铺为计算输出平铺中的P元素所需的输入N元素的集合。图7.11展示了输入平铺（左侧的阴影区域）与输出平铺（右侧的阴影区域）的对应关系。注意，输入平铺的尺寸需要在每个方向上扩展滤波器的半径（在本例中为2），以确保包含计算输出平铺边缘的P元素所需的所有边界输入元素。这种扩展可能使得输入平铺比输出平铺大得多。

![image](https://github.com/user-attachments/assets/488356de-fabd-4410-afad-67267be9f8f3)
> 图7.11 二维卷积中的输入平铺与输出平铺。

在这个玩具示例中，每个输出平铺包含4<sup>2</sup>=16个P元素，而每个输入平铺包含(4+4)<sup>2</sup>=8<sup>2</sup>=64个元素。在这种情况下，输入平铺比输出平铺大4<sup>3</sup>倍。然而，这个大的比例是因为我们假设了一个非常小的输出平铺尺寸以便于可视化。在实际应用中，输出平铺的尺寸会大得多，输入平铺尺寸和输出平铺尺寸的比例会更接近1.0。例如，如果输出尺寸是16×16=256，使用相同的5×5滤波器，输入平铺的尺寸将是(16+4)<sup>2</sup>=400。输入平铺尺寸和输出尺寸之间的比例约为1.6。虽然这个比例远小于4，但它表明即使对于实际的输出平铺尺寸，输入平铺的尺寸仍然可以显著大于输出平铺。

在本节中，我们介绍了一类平铺卷积算法，其中块中的所有线程首先协同加载输入平铺到共享内存中，然后通过从共享内存中访问输入元素来计算输出平铺的元素。这种策略对于读者来说应该很熟悉；它类似于第5章《内存架构与数据局部性》中讨论的平铺矩阵乘法算法。主要的区别在于，第5章中的平铺矩阵乘法算法假设输入平铺和输出平铺的尺寸相同，而卷积中的输入平铺比输出平铺大。这种输入平铺尺寸与输出平铺尺寸之间的差异使得平铺卷积内核的设计更加复杂。

有两种简单的线程组织方式来解决输入平铺尺寸和输出平铺尺寸之间的差异。第一种方式是启动线程块，其尺寸与输入平铺的尺寸匹配。这简化了输入平铺的加载，因为每个线程只需要加载一个输入元素。然而，由于块的尺寸大于输出平铺的尺寸，在计算输出元素时需要禁用一些线程，这可能会降低执行资源的利用效率。第二种方法启动的块，其尺寸与输出平铺的尺寸匹配。一方面，这种策略使得输入平铺的加载更加复杂，因为线程需要迭代以确保加载所有输入平铺元素。另一方面，它简化了输出元素的计算，因为块的尺寸与输出平铺相同，在计算输出元素时不需要禁用任何线程。我们将基于第一种线程组织方式来设计一个内核，并将第二种组织方式留作练习。

图7.12展示了基于第一种线程组织方式的内核。每个线程首先计算它负责加载或计算的输入或输出元素的列索引（col）和行索引（row）（第06-07行）。内核分配了一个与输入平铺尺寸相同的共享内存数组`N_s`（第09行），并将输入平铺加载到共享内存数组中（第10-15行）。第10行的条件用于检查每个线程尝试加载的输入平铺元素是否是边界单元。如果是，线程不会执行内存加载，而是将零放入共享内存中。所有线程执行一个屏障同步（第15行），以确保整个输入平铺都已经加载到共享内存中，然后才允许任何线程继续计算输出元素。

```cuda
#define IN_TILE_DIM 32
#define OUT_TILE_DIM((IN_TILE_DIM) - 2*(FILTER_RADIUS))
__constant__ float F_c[2*FILTER_RADIUS+1][2*FILTER_RADIUS+1];
__global__ void convolution_tiled_2D_const_mem_kernel(float *N, float *P, int width, int height){

    int col = blockIdx.x*OUT_TILE_DIM + threadIdx.x - FILTER_RADIUS;
    int row = blockIdx.y*OUT_TILE_DIM + threadIdx.y - FILTER_RADIUS;
    // 加载输入平铺
    __share__ N_s[IN_TILE_DIM][IN_TILE_DIM];
    if(row >= 0 && row < height && col >= 0 && col < width){
        N_s[threadIdx.y][threadIdx.x] = N[row*width + col];
    }
    else{
        N_s[threadIdx.y][threadIdx.x] = 0.0;
    }
    __syncthreads();
    // 计算输出元素
    int tileCol = threadIdx.x - FILTER_RADIUS;
    int tileRow = threadIdx.y - FILTER_RADIUS;
    // 关闭块边缘的线程
    if(col >= 0 && tileCol < OUT_TILE_DIM && tileRow >= 0 && tileRow < OUT_TILE_DIM){
        float Pvalue = 0.0f;
        for(int fRow = 0; fRow < 2*FILTER_RADIUS+1; fRow++){
            for(int fCol = 0; fCol < 2*FILTER_RADIUS+1; fCol++){
                Pvalue += F[fRow][fCol]*N_s[tileRow+fRow][tileCol+fCol];
            }
        }
        P[row*width+col] = Pvalue;
    }
}
```
> 图7.12 使用常量内存的平铺二维卷积内核。

现在所有的输入平铺元素都在`N_s`数组中，每个线程可以使用`N_s`元素计算它们的输出P元素值。请记住，输出平铺比输入平铺小，且块的尺寸与输入平铺的尺寸相同，因此每个块中的线程仅会用于计算输出平铺的部分元素。我们可以通过多种方式选择用于计算的线程。我们使用了一种设计，禁用`FILTER_RADIUS`外层的线程，如图7.13所示。

![image](https://github.com/user-attachments/assets/8cfe96ce-fcbf-4e90-b368-71bcf9ef2023)    
> 图7.13 展示了如何使用输入平铺元素的线程组织的小示例

图7.13展示了使用3×3滤波器（`FILTER_RADIUS`=1）、8×8输入平铺、8×8块和6×6输出平铺的卷积小示例。图7.13的左侧展示了输入平铺和线程块。由于它们的尺寸相同，它们被重叠在一起。根据我们的设计，我们禁用`FILTER_RADIUS`=1的外层线程。图7.13左侧中心的重线框包含了用于计算输出平铺元素的活跃线程。在这个示例中，活跃线程的`threadIdx.x`和`threadIdx.y`值都从1到6。图7.13还展示了活跃线程到输出平铺元素的映射：活跃线程（`tx`，`ty`）将使用输入平铺元素的补丁（其左上角是输入平铺的元素`(tx - FILTER_RADIUS, ty - FILTER_RADIUS)`）计算输出元素（`tx - FILTER_RADIUS, ty - FILTER_RADIUS`）。这在图7.12的第17-18行中有所反映，其中列索引（`tileCol`）和行索引（`tileRow`）分别被赋值为`threadIdx.x - FILTER_RADIUS`和`threadIdx.y - FILTER_RADIUS`。

在我们的小示例中，图7.13中的线程（1,1）的`tileCol`和`tileRow`分别为0和0。因此，线程（1,1）使用输入平铺左上角为`N_s[0][0]`的3×3补丁计算输出平铺元素（0,0）。图7.12的第24-28行中的`fRow-fCol`循环遍历补丁并生成输出元素。块中的线程（1,1）将遍历左上角为`N_s[0][0]`的补丁，而线程（5,5）将遍历左上角为`N_s[5][5]`的补丁。

在第06-07行中，`blockIdx.x*OUT_TILE_DIM`和`blockIdx.y*OUT_TILE_DIM`分别是分配给块的输出平铺的水平和垂直P数组索引。如前所述，`threadIdx.x-FILTER_RADIUS`和`threadIdx.y-FILTER_RADIUS`给出了平铺中的偏移量。因此，行变量和列变量提供了分配给每个活跃线程的输出元素的索引。每个线程使用这两个索引在第29行写入输出元素的最终值。

图7.12中的平铺二维卷积内核比图7.9中的基本内核长且复杂得多。我们引入了额外的复杂性，以减少对N元素的DRAM访问次数。目标是提高算术运算与全局内存访问的比率，以便性能不受DRAM带宽的限制或受到较少限制。请回忆一下第7.4节中，图7.9中的内核的算术运算与全局内存访问的比率为0.5 OP/B。现在我们来推导图7.12中的内核的比率。

对于处理数据边缘的平铺的块，处理边界单元的线程不会对这些边界单元执行任何内存访问。这减少了这些块的内存访问次数。我们可以通过列举使用每个边界单元的线程数量来计算减少的内存访问次数。然而，对于大型输入数组，小掩码大小的边界单元的影响将是微不足道的。因此，在计算平铺卷积内核的算术运算与全局内存访问比率时，我们将忽略边界单元的影响，只考虑内部线程块，其中的边界单元不是边界单元。

现在我们计算图7.12中平铺内核的算术运算与全局内存访问比率。每个分配给输出平铺元素的线程对滤波器的每个元素执行一次乘法和一次加法。因此，内部块中的线程总共执行`OUT_TILE_DIM`^2*(2*`FILTER_RADIUS` + 1)^2*2个算术操作。至于全局内存访问，所有全局内存访问已转移到将N元素加载到共享内存的代码中。每个分配给输入平铺元素的线程加载一个4字节的输入值。因此，每个内部块加载`IN_TILE_DIM^2*4=(OUT_TILE_DIM+2*FILTER_RADIUS)^2*4`字节。因此，平铺内核的算术运算与全局内存访问比率为

$$ \frac{OUT_TILE_DIM^{2} * (2*FILTER_RADIUS + 1)+{2} * 2}{(OUT_TILE_DIM + 2 * FILTER_RADIUS)^{2} * 4} $$

对于我们的示例，使用5×5滤波器和32×32输入平铺（28×28输出平铺），比率为9.57 OP/B。32×32的输入平铺是当前GPU上可实现的最大尺寸。然而，我们可以对平铺尺寸进行渐近分析，以获得此计算的算术运算与全局内存访问比率的上限。如果`OUT_TILE_DIM`远大于`FILTER_RADIUS`，我们可以认为`OUT_TILE_DIM+2*FILTER_RADIUS`大致为`OUT_TILE_DIM`。这简化了表达式为(2*`FILTER_RADIUS`+1)^2*2/4。这个结果应该很直观。在原始算法中，每个N元素被大约(2×`FILTER_RADIUS`+1)<sup>2</sup>线程冗余加载，每个线程对其执行两次算术操作。因此，如果平铺尺寸是无限大的，并且每个4字节的元素仅加载一次到共享内存中，则比率应该是(2*`FILTER_RADIUS`+1)^2*2/4。

图7.14展示了不同滤波器尺寸下平铺卷积内核的算术运算与全局内存访问比率如何随平铺尺寸变化，包括渐近界限。5×5滤波器的比率上限是12.5 OP/B。然而，实际在32×32线程块大小限制下实现的比率是9.57 OP/B。对于更大的滤波器，例如图7.14底行中的9×9，比例上限是40.5 OP/B。然而，实际在32×32线程块大小限制下实现的比率是22.78 OP/B。因此，我们观察到较大的滤波器尺寸具有更高的比率，因为每个输入元素被更多的线程使用。然而，较大的滤波器尺寸也有更高的界限和实际实现之间的差距，因为更多的边界元素迫使输出平铺更小。

读者在使用小的块和平铺尺寸时应始终小心。它们可能导致内存访问减少的程度远低于预期。例如，在图7.14中，8×8块（输入平铺）在5×5滤波器下的比率仅为3.13 OP/B。在实践中，由于片上内存不足，特别是在3D卷积中，所需的片上内存随着平铺尺寸的增加而迅速增长，因此通常使用较小的平铺尺寸。

![image](https://github.com/user-attachments/assets/bc0156c0-f184-4b4f-9222-ce474b512c68)
> 图7.14

## 7.5 使用缓存处理边界单元的平铺卷积

在图7.12中，代码的复杂性很大程度上与输入平铺和块的尺寸大于输出平铺的事实有关，因为需要加载边界单元。回顾一下，块的输入平铺的边界单元也是相邻平铺的内部元素。例如，在图7.11中，输入平铺的浅灰色边界单元也是相邻块的输入平铺的内部元素。由于块在需要其边界单元时，这些边界单元很可能已经由于相邻块的访问而存在于L2缓存中。因此，对这些边界单元的内存访问可能自然地从L2缓存中服务，而不会导致额外的DRAM流量。也就是说，我们可以保留对这些边界单元的原始N元素的访问，而不是将它们加载到`N_ds`中。我们现在介绍一种使用相同维度的输入和平铺的平铺卷积算法，只加载每个平铺的内部元素到共享内存中。

图7.15展示了一个使用缓存处理边界单元的二维卷积内核。在这个平铺内核中，共享内存`N_ds`数组只需要保存平铺的内部元素。因此，输入平铺和输出平铺的尺寸是相同的，这被定义为常量`TILE_DIM`（第1行）。通过这种简化，`N_s`被声明为在x和y维度上都有TILE_DIM个元素（第6行）。

```cuda
#define TILE_DIM 32
__constant__ float F_c[2*FILTER_RADIUS+1][2*FILTER_RADIUS+1];
__global__ void convolution_cache_tiled_2D_const_mem_kernel(float *N, float *P, int width, int height){
    int col = blockIdx.x*TILE_DIM + threadIdx.x;
    int row = blockIdx.y*TILE_DIM + threadIdx.y;
    // 加载输入平铺
    __shared__ float N_s[TILE_DIM][TILE_DIM];
    if(row < height && col < width){
        N_s[threadIdx.y][threadIdx.x] = N[row*width + col];
    }
    else{
        N_s[threadIdx.y][threadIdx.x] = 0.0;
    }
    __syncthreads();
    // 计算输出元素
    // 关闭块边缘的线程
    if(col < width && row < height){
        float Pvalue = 0.0f;
        for(int fRow = 0; fRow < 2*FILTER_RADIUS+1; fRow++){
            for(int fCol = 0; fCol < 2*FILTER_RADIUS+1; fCol++){
                if(threadIdx.x - FILTER_RADIUS + fCol >= 0 &&
                   threadIdx.x - FILTER_RADIUS + fCol < TILE_DIM &&
                   threadIdx.y - FILTER_RADIUS + fRow >= 0 &&
                   threadIdx.y - FILTER_RADIUS + fRow < TILE_DIM
                ){
                    Pvalue += F_c[fRow][fCol] * N_s[threadIdx.y - FILTER_RADIUS + fRow][threadIdx.x - FILTER_RADIUS + fCol];
                }
                else{
                    if(row - FILTER_RADIUS + fRow >= 0 &&
                       row - FILTER_RADIUS + fRow < height &&
                       col - FILTER_RADIUS + fCol >= 0 &&
                       col - FILTER_RADIUS + fCol < width
                    ){
                        Pvalue += F_c[fRow][fCol] * N[(row - FILTER_RADIUS + fRow) * width + (col - FILTER_RADIUS + fCol)];
                    }
                }
            }
        }
        P[row * width + col] = Pvalue;
    }
}
```
> 图7.15 使用缓存处理边界单元的平铺二维卷积内核，并使用常量内存存储F。

由于输入平铺和输出平铺的尺寸相同，线程块可以使用相同的尺寸进行启动。因此，`N_s`元素的加载变得更简单，因为每个线程可以直接加载与其分配的输出元素具有相同x和y坐标的输入元素（第4-5行和第7-11行）。加载输入元素的条件也简化为第7行：
由于内核不再将边界单元加载到共享内存中，因此不再存在加载鬼影单元的危险。因此，条件只需检查平铺是否超出了输入数据的有效范围。

然而，计算P元素的循环体变得更复杂。它需要添加条件来检查是否使用了边界单元和鬼影单元。边界单元的处理是通过第17-20行的条件完成的，这些条件测试输入元素是否落在输入平铺的内部。如果是，该元素从共享内存中访问。如果不是，第24-27行的条件检查这些边界单元是否是鬼影单元。如果是，则不对该元素采取任何操作，因为我们假设鬼影值为0。否则，该元素从全局内存中访问。读者应验证处理鬼影单元的条件类似于图7.7中使用的条件。

图7.15中的内核相比于图7.12中的内核的一个微妙优势是，它的块大小、输入平铺大小和输出平铺大小可以相同且可以是2的幂。由于图7.12中的内核输入平铺大小和输出平铺大小不同，因此在该内核的执行过程中可能会有更多的内存分歧和控制分歧。

## 7.6 总结

在本章中，我们研究了卷积作为一个重要的并行计算模式。虽然卷积用于许多应用，如计算机视觉和视频处理，但它也代表了许多并行算法的基础模式。例如，可以将部分微分方程求解中的模板算法视为卷积的一个特例；这将在第8章“模板”中讨论。另一个例子是计算网格点的力或势值也可以视为卷积的一个特例，这将在第17章“迭代磁共振成像重建”中介绍。

我们还将在第16章“深度学习”中应用本章中学到的许多卷积神经网络知识。我们展示了一个基本的并行卷积算法，其实现将受到DRAM带宽的限制，以访问输入和滤波器元素。接着，我们介绍了常量内存和对内核及主机代码的简单修改，以利用常量缓存并消除几乎所有的DRAM访问操作。我们进一步介绍了一种平铺并行卷积算法，它通过利用共享内存来减少DRAM带宽消耗，但引入了更多的控制流分歧和编程复杂性。最后，我们展示了一种利用L1和L2缓存处理边界单元的平铺并行卷积算法。

我们分析了平铺的好处，即提升的算术运算与全局内存访问比率。这个分析是一项重要技能，对于理解其他模式中平铺的好处也很有用。通过分析，我们可以了解到小平铺尺寸的限制，这在大滤波器和3D卷积中尤为明显。

虽然我们只展示了1D和2D卷积的内核示例，但这些技术同样适用于3D卷积。一般来说，由于维度更高，输入和输出数组的索引计算会更复杂。此外，由于需要遍历多个维度以加载平铺和/或计算输出值，每个线程将有更多的循环嵌套。我们鼓励读者将这些高维内核作为家庭作业练习完成。

## 习题

1. 计算图7.3中P[0]的值。
2. 考虑对数组N = {4, 1, 3, 2, 3}进行1D卷积，滤波器F = {2, 1, 4}。结果输出数组是什么？
3. 你认为以下1D卷积滤波器在做什么？
   a. [0 1 0]
   b. [0 0 1]
   c. [1 0 0]
   d. [2/1 0 1/2]
   e. [1/3 1/3 1/3]
4. 考虑对大小为N的数组进行1D卷积，滤波器大小为M：
   a. 总共有多少个鬼影单元？
   b. 如果鬼影单元被视为乘法（乘以0），则执行了多少次乘法？
   c. 如果鬼影单元不被视为乘法，则执行了多少次乘法？
5. 考虑对大小为N × N的方形矩阵进行2D卷积，滤波器大小为M × M：
   a. 总共有多少个鬼影单元？
   b. 如果鬼影单元被视为乘法（乘以0），则执行了多少次乘法？
   c. 如果鬼影单元不被视为乘法，则执行了多少次乘法？
6. 考虑对大小为N<sub>1</sub> × N<sub>2</sub>的矩形矩阵进行2D卷积，滤波器大小为M<sub>1</sub> × M<sub>2</sub>：
   a. 总共有多少个鬼影单元？
   b. 如果鬼影单元被视为乘法（乘以0），则执行了多少次乘法？
   c. 如果鬼影单元不被视为乘法，则执行了多少次乘法？
7. 考虑对大小为N × N的数组使用图7.12中显示的内核进行2D平铺卷积，滤波器大小为M × M，输出平铺大小为T × T：
   a. 需要多少个线程块？
   b. 每个块需要多少个线程？
   c. 每个块需要多少共享内存？
   d. 如果使用图7.15中的内核，重复相同的问题。
8. 修改图7.7中的2D内核以执行3D卷积。
9. 修改图7.9中的2D内核以执行3D卷积。
10. 修改图7.12中的平铺2D内核以执行3D卷积。
