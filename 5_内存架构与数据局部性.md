# 5_内存架构和数据局部性

* 5.1 [内存访问效率的重要性](https://github.com/tunglinwood/CUDA/blob/main/5_%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%B1%80%E9%83%A8%E6%80%A7.md#51-%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%95%88%E7%8E%87%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7)
* 5.2 [CUDA 内存类型](https://github.com/tunglinwood/CUDA/blob/main/5_%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%B1%80%E9%83%A8%E6%80%A7.md#52-cuda-%E5%86%85%E5%AD%98%E7%B1%BB%E5%9E%8B)
* 5.3 [通过分块减少内存流量](https://github.com/tunglinwood/CUDA/blob/main/5_%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%B1%80%E9%83%A8%E6%80%A7.md#53-%E7%93%A6%E7%89%87%E6%8A%80%E6%9C%AF%E4%BB%A5%E5%87%8F%E5%B0%91%E5%86%85%E5%AD%98%E6%B5%81%E9%87%8F)
* 5.4 [分块矩阵乘法核](https://github.com/tunglinwood/CUDA/blob/main/5_%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%B1%80%E9%83%A8%E6%80%A7.md#54-%E7%93%A6%E7%89%87%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E5%86%85%E6%A0%B8)
* 5.5 [边界检查](https://github.com/tunglinwood/CUDA/blob/main/5_%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%B1%80%E9%83%A8%E6%80%A7.md#55-%E8%BE%B9%E7%95%8C%E6%A3%80%E6%9F%A5)
* 5.6 [内存使用对占用率的影响](https://github.com/tunglinwood/CUDA/blob/main/5_%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%B1%80%E9%83%A8%E6%80%A7.md#56-%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E5%AF%B9%E5%8D%A0%E7%94%A8%E7%8E%87%E7%9A%84%E5%BD%B1%E5%93%8D)
* 5.7 [总结](https://github.com/tunglinwood/CUDA/blob/main/5_%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%B1%80%E9%83%A8%E6%80%A7.md#57-%E6%80%BB%E7%BB%93)
* [练习]()

到目前为止，我们已经学习了如何编写 CUDA 内核函数以及如何配置和协调大量线程的执行。我们还研究了当前 GPU 硬件的计算架构以及线程如何在硬件上调度执行。在本章中，我们将重点关注 GPU 的片上内存架构，并开始研究如何组织和定位数据，以便大量线程高效访问。到目前为止，我们研究的 CUDA 内核可能只能达到底层硬件潜在速度的一小部分。这种性能较差的原因是全局内存（通常由片外 DRAM 实现）通常具有较长的访问延迟（数百个时钟周期）和有限的访问带宽。尽管可以通过大量可用线程来理论上容忍长时间的内存访问延迟，但很容易遇到全局内存访问路径上的流量拥堵情况，这会阻止大多数线程取得进展，从而使流式多处理器（SM）中的一些内核处于空闲状态。为了绕过这种拥堵，GPU 提供了许多额外的片上内存资源来访问数据，这些资源可以消除大部分进出全局内存的流量。在本章中，我们将研究如何使用不同类型的内存来提升 CUDA 内核的执行性能。

## 5.1 内存访问效率的重要性
我们可以通过计算图 3.11 中矩阵乘法内核代码执行最多部分的预期性能水平来说明内存访问效率的影响，如图 5.1 部分复制的代码所示。就执行时间而言，内核中最重要的部分是执行 M 的一行与 N 的一列点积的 for 循环。

在循环的每次迭代中，执行一次浮点乘法和一次浮点加法需要两次全局内存访问。全局内存访问从 M 和 N 数组中获取元素。浮点乘法操作将这两个元素相乘，浮点加法操作将积累结果累加到 `Pvalue` 中。因此，浮点运算（FLOP）与从全局内存访问的字节数（B）的比率为 2 FLOP 对 8 B，即 0.25 FLOP/B。我们将此比率称为计算与全局内存访问比率，定义为程序区域内从全局内存访问每个字节时执行的 FLOP 数量。此比率有时在文献中也称为算术强度或计算强度。

计算与全局内存访问比率对 CUDA 内核的性能有重大影响。例如，Ampere A100 GPU 的峰值全局内存带宽为 1555 GB/秒。由于矩阵乘法内核执行 0.25 OP/B，全局内存带宽限制了内核可以执行的单精度 FLOP 的吞吐量为 389 GFLOPS（每秒千兆浮点运算），即 1555 GB/秒乘以 0.25 FLOP/B 得出。然而，389 GFLOPS 仅是 A100 GPU 峰值单精度操作吞吐量的 2%，即 19,500 GFLOPS。A100 还配备了用于加速矩阵乘法操作的专用单元，称为张量核心。如果考虑到 A100 的张量核心峰值单精度浮点吞吐量为 156,000 GFLOPS，那么 389 GFLOPS 仅是峰值的 0.25%。因此，矩阵乘法内核的执行严重受到将数据从内存传输到 GPU 核心的速率的限制。我们称那些执行速度受内存带宽限制的程序为内存受限程序。

```cuda
for (int k = 0; k < Width; ++k){
	Pvalue += M[row*Width+k] * N[k*Width+col];
}
```
> 图 5.1 常见矩阵乘法操作内核

> ### 屋顶线模型
> 屋顶线模型是一种评估应用程序相对于其运行硬件的限制所实现的性能的视觉模型。下图显示了一个基本的屋顶线模型。在 x 轴上，我们有算术或计算强度，单位是 FLOP/B。它反映了应用程序在加载每字节数据时完成的工作量。在 y 轴上，我们有计算吞吐量，单位是 GFLOPS。图中的两条线反映了硬件的限制。水平线由硬件可以维持的峰值计算吞吐量（GFLOPS）决定。从原点开始的正斜线由硬件可以维持的峰值内存带宽决定。图中的点代表应用程序，其操作强度在 x 轴上，其实现的计算吞吐量在 y 轴上。当然，这些点将在两条线下方，因为它们不能超过硬件的峰值吞吐量。
> ![image](https://github.com/user-attachments/assets/da47c1a3-b7ab-48a0-8bc9-ab966da3a5fb)
> 点相对于这两条线的位置告诉我们应用程序的效率。接近两条线的点表明应用程序有效地使用了内存带宽或计算单元，而远低于两条线的应用程序表明资源使用效率低。两条线交点表示应用程序从内存受限转换为计算受限的计算强度值。计算强度较低的应用程序是内存受限的，无法达到峰值吞吐量，因为它们受内存带宽限制。计算强度较高的应用程序是计算受限的，不受内存带宽限制。
> 例如，点 A1 和 A2 都代表内存受限的应用程序，而 A3 代表计算受限的应用程序。A1 有效地使用了资源，接近峰值内存带宽，而 A2 则没有。对于 A2，可能还有进一步优化的空间，通过提高内存带宽利用率来提高吞吐量。然而，对于 A1，提高吞吐量的唯一方法是提高应用程序的计算强度。

要实现该内核的更高性能，我们需要通过减少执行的全局内存访问次数来增加内核的计算与全局内存访问比率。例如，要充分利用 A100 GPU 提供的 19,500 GFLOPS，至少需要 12.5 OP/B 的比率，即（19,500 GOP/秒）/（1555 GB/秒）。这意味着每访问 4 字节的浮点值，必须执行约 50 次浮点操作！实现这种比率的程度取决于当前计算中的固有数据重用程度。我们建议读者参考“屋顶线模型”边栏来分析程序的计算强度及其潜在性能。

正如我们将看到的，矩阵乘法提供了减少全局内存访问次数的机会，可以通过相对简单的技术来实现。矩阵乘法函数的执行速度可能因全局内存访问次数的减少而有数量级的差异。因此，矩阵乘法提供了一个很好的初始例子来展示这些技术。本章介绍了一种常用的减少全局内存访问次数的技术，并展示了该技术在矩阵乘法中的应用。

## 5.2 CUDA 内存类型

CUDA 设备包含几种类型的内存，帮助程序员改善计算与全局内存访问的比例。图 5.2 展示了这些 CUDA 设备内存。在图的底部，我们可以看到全局内存和常量内存。这两种内存类型都可以被主机写入（W）和读取（R）。全局内存还可以被设备写入和读取，而常量内存支持设备的短延迟、高带宽的只读访问。我们在第 2 章《异构数据并行计算》中介绍了全局内存，而常量内存在第 7 章《卷积》中将会详细讨论。

![image](https://github.com/user-attachments/assets/3ed9ce9a-9f9c-4e1d-8736-faf209d9c604)
> FIGURE 5.2 CUDA 设备内存模型的（不完整）概述。图中未显示的一个重要类型的 CUDA 内存是纹理内存，因为本书不涉及其使用。

另一种内存类型是局部内存，也可以读写。局部内存实际上位于全局内存中，具有类似的访问延迟，但在线程之间不共享。每个线程有自己的一部分全局内存，作为其私有局部内存，用于存放线程私有的数据，但这些数据不能分配到寄存器中。这些数据包括静态分配的数组、溢出的寄存器以及线程调用栈的其他元素。

图 5.2 中的寄存器和共享内存是片上内存。驻留在这些类型内存中的变量可以以非常高的速度以高度并行的方式访问。寄存器分配给单个线程；每个线程只能访问自己的寄存器（参见“CPU 与 GPU 寄存器架构”侧边栏）。一个内核函数通常使用寄存器来保存每个线程私有的、频繁访问的变量。共享内存分配给线程块；块中的所有线程可以访问为块声明的共享内存变量。共享内存是线程通过共享输入数据和中间结果进行合作的有效手段。通过在 CUDA 变量声明中使用其中一种 CUDA 内存类型，CUDA 程序员可以指定变量的可见性和访问速度。

> ### CPU 与 GPU 寄存器架构
> CPU 和 GPU 之间不同的设计目标导致了不同的寄存器架构。正如我们在第 4 章《计算架构与调度》中看到的，当 CPU 在不同线程之间进行上下文切换时，它们将外出线程的寄存器保存到内存中，并从内存中恢复入驻线程的寄存器。相比之下，GPU 通过在处理块的寄存器文件中保持所有调度线程的寄存器来实现零开销调度。这样，线程之间的切换是瞬时的，因为入驻线程的寄存器已经在寄存器文件中。因此，GPU 的寄存器文件需要比 CPU 的寄存器文件大得多。
>
> 我们在第 4 章《计算架构与调度》中还看到，GPU 支持动态资源分配，其中一个 SM 可以为每个线程分配少量寄存器并执行大量线程，或者为每个线程分配更多寄存器并执行较少线程。因此，GPU 寄存器文件需要设计以支持这种动态寄存器分配。相比之下，CPU 寄存器架构为每个线程分配固定数量的寄存器，而不考虑线程对寄存器的实际需求。

为了全面理解寄存器、共享内存和全局内存之间的差异，我们需要详细了解这些不同内存类型在现代处理器中的实现和使用。如第 4 章《计算架构与调度》的“线程束和 SIMD 硬件”侧边栏中所讨论的，几乎所有现代处理器都源于 1945 年约翰·冯·诺依曼提出的模型，如图 5.3 所示。CUDA 设备也不例外。

![image](https://github.com/user-attachments/assets/e0632545-f06c-4ba6-b94a-ccf91020aaba)
> FIGURE 5.3 基于冯·诺依曼模型的现代计算机中的内存与寄存器。

CUDA 设备中的全局内存对应于图 5.3 中的“内存”框。处理器框对应于我们今天常见的处理器芯片边界。全局内存位于处理器芯片之外，使用 DRAM 技术实现，这意味着访问延迟较长且带宽相对较低。寄存器对应于冯·诺依曼模型中的“寄存器文件”。寄存器文件位于处理器芯片上，这意味着与全局内存相比，访问延迟非常短且带宽极高。在典型设备中，所有 SM 的寄存器文件的总访问带宽至少比全局内存高两个数量级。此外，每当一个变量存储在寄存器中时，其访问不再消耗离芯片的全局内存带宽。这将反映为计算与全局内存访问比的提高。

更微妙的一点是，每次访问寄存器涉及的指令比访问全局内存的指令要少。大多数现代处理器中的算术指令具有“内置”的寄存器操作数。例如，一个浮点加法指令可能如下：

```cuda
fadd r1, r2, r3
```

其中 r2 和 r3 是指定寄存器文件中输入操作数值位置的寄存器号。存储浮点加法结果值的位置由 r1 指定。因此，当算术指令的操作数在寄存器中时，无需额外的指令将操作数值提供给算术和逻辑单元（ALU），在 ALU 中进行算术计算。

另一方面，如果操作数值在全局内存中，处理器需要执行内存加载操作以使操作数值可用。例如，如果浮点加法指令的第一个操作数在全局内存中，涉及的指令可能如下：

```cuda
load r2, r4, offset
fadd r1, r2, r3
```

其中 `load` 指令将偏移值加到 r4 的内容上，以形成操作数值的地址。然后，它访问全局内存并将值放入寄存器 r2 中。一旦操作数值在 r2 中，`fadd` 指令使用 r2 和 r3 中的值进行浮点加法，并将结果放入 r1 中。由于处理器每个时钟周期只能获取和执行有限数量的指令，因此带有额外加载的版本可能比没有额外加载的版本需要更多时间来处理。这是将操作数放入寄存器中可以提高执行速度的另一个原因。

最后，还有另一个微妙的理由说明为什么将操作数值放入寄存器中是更好的。在现代计算机中，从寄存器文件中访问值消耗的能量至少比从全局内存中访问值少一个数量级。从寄存器中访问值在能效方面比从全局内存中访问值具有巨大的优势。我们将很快详细讨论访问这两种硬件结构在现代计算机中的速度和能量差异。另一方面，正如我们很快将学到的，今天的 GPU 中每个线程可用的寄存器数量非常有限。正如我们在第 4 章《计算架构与调度》中看到的，如果应用程序的占用率在满占用场景中超出了限制，则会降低。因此，我们也需要尽可能避免过度使用这一有限资源。

图 5.4 展示了 CUDA 设备中的共享内存和寄存器。尽管它们都是片上内存，但在功能和访问成本上有很大差异。共享内存设计为处理器芯片上的内存空间的一部分。当处理器访问共享内存中的数据时，需要执行内存加载操作，就像访问全局内存中的数据一样。然而，由于共享内存在芯片上，因此它的访问延迟和吞吐量远远高于全局内存。由于需要执行加载操作，共享内存的延迟较长且带宽低于寄存器。在计算机架构术语中，共享内存是一种刮痕内存。

![image](https://github.com/user-attachments/assets/164dde7a-c4a4-4674-b6f4-dc74e02b5a6c)
> FIGURE 5.4 CUDA 设备 SM 中的共享内存与寄存器的比较。

CUDA 中共享内存和寄存器之间的一个重要区别是，驻留在共享内存中的变量可以被块中的所有线程访问。这与寄存器数据不同，寄存器数据是线程私有的。也就是说，共享内存设计用于支持线程块中线程之间的数据高效、高带宽共享。如图 5.4 所示，CUDA 设备 SM 通常使用多个处理单元，以允许多个线程在这些处理单元上同时进展（参见第 2 章《异构数据并行计算》中的“线程”侧边栏）。线程在块中可以分布在这些处理单元上。因此，这些 CUDA 设备中共享内存的硬件实现通常设计为允许多个处理单元同时访问其内容，以支持线程块中线程之间的高效数据共享。我们将学习几种重要的并行算法，这

些算法可以从线程之间的高效数据共享中获得巨大的好处。

到现在为止应该很清楚，寄存器、局部内存、共享内存和全局内存各有不同的功能、延迟和带宽。因此，了解如何声明一个变量以使其驻留在目标内存类型中是非常重要的。表 5.1 展示了将程序变量声明到各种内存类型中的 CUDA 语法。每种声明也为声明的 CUDA 变量赋予了作用域和生命周期。作用域确定可以访问变量的线程集：仅一个线程、块中的所有线程或所有网格中的所有线程。如果变量的作用域是单个线程，则为每个线程创建该变量的私有版本；每个线程只能访问其私有版本的变量。例如，如果一个内核声明了一个作用域为线程的变量，并且它以一百万个线程启动，则会创建一百万个该变量的版本，以便每个线程初始化并使用自己的变量版本。

|Variable declaration |Memory |Scope |Lifetime|
|:-|:-|:-|:-|
|Automatic variables other than arrays |Register |Thread |Grid|
|Automatic array variables |Local |Thread |Grid|
|__device__ __shared__ int SharedVar; |Shared |Block |Grid|
|__device__ int GlobalVar; |Global |Grid |Application|
|__device__ __constant__ int ConstVar; |Constant |Grid |Application|

| 变量声明 | 内存 | 作用域 | 生命周期 |
|:--|:--|:--|:--|
| 除数组外的自动变量 | 寄存器 | 线程 | 网格 |
| 自动数组变量 | 局部 | 线程 | 网格 |
| __device__ __shared__ int SharedVar; | 共享 | 块 | 网格 |
| __device__ int GlobalVar; | 全局 | 网格 | 应用 |
| __device__ __constant__ int ConstVar; | 常量 | 网格 | 应用 |

> 表 5.1 CUDA 变量声明类型限定符及其属性。

生命周期告诉我们变量在程序执行期间可用的时段：是在网格执行期间还是在整个应用程序期间。如果变量的生命周期在网格执行期间，则必须在内核函数体内声明，并且仅对内核的代码可用。如果内核被多次调用，则变量的值不会在这些调用之间保持。每次调用都必须初始化变量才能使用。另一方面，如果变量的生命周期是整个应用程序，则必须在任何函数体之外声明。这些变量的内容在应用程序的整个执行期间保持，并对所有内核可用。

我们称没有数组的变量为标量变量。如表 5.1 所示，所有在内核和设备函数中声明的自动标量变量都被存储在寄存器中。这些自动变量的作用域在单个线程内。当内核函数声明一个自动变量时，为每个执行该内核函数的线程生成该变量的私有副本。当线程终止时，所有其自动变量也会消失。

在图 5.1 中，变量 `blurRow`、`blurCol`、`curRow`、`curCol`、`pixels` 和 `pixVal` 都是自动变量，属于这一类别。注意，这些变量的访问速度极快且并行，但必须小心不要超出硬件实现中的寄存器存储限制。使用大量寄存器可能会对每个 SM 的占用率产生负面影响，正如我们在第 4 章《计算架构与调度》中看到的那样。

自动数组变量不存储在寄存器中。而是存储在线程的局部内存中，可能会导致较长的访问延迟和潜在的访问拥堵。这些数组的作用域与自动标量变量相同，限于单个线程。也就是说，为每个线程创建并使用一个自动数组的私有版本。一旦线程终止执行，其自动数组变量的内容也会消失。从我们的经验来看，在内核函数和设备函数中很少需要使用自动数组变量。

如果变量声明之前有 `__shared__` 关键字（每个 "__" 由两个 "_" 字符组成），则声明了一个 CUDA 共享变量。在声明中也可以在 `__shared__` 前添加一个可选的 `__device__` 以达到相同的效果。这种声明通常在内核函数或设备函数中进行。共享变量驻留在共享内存中。共享变量的作用域在线程块内；即块中的所有线程看到相同版本的共享变量。在内核执行期间，为每个块创建并使用共享变量的私有版本。共享变量的生命周期是内核执行的持续时间。当内核终止网格执行时，其共享变量的内容也会消失。如前所述，共享变量是线程在块内合作的有效手段。从共享内存中访问共享变量非常快且高度并行。CUDA 程序员经常使用共享变量来保存全局内存数据中在内核执行阶段频繁使用和重用的部分。可能需要调整用于创建执行阶段的算法，重点关注全局内存数据的较小部分，如第 5.4 节中的矩阵乘法所示。

如果变量声明之前有 `__constant__` 关键字（每个 "__" 由两个 "_" 字符组成），则声明了一个 CUDA 常量变量。在 `__constant__` 前添加一个可选的 `__device__` 也能达到相同的效果。常量变量的声明必须在任何函数体之外。常量变量的作用域是所有网格，即所有网格中的所有线程看到相同版本的常量变量。常量变量的生命周期是整个应用程序执行。常量变量通常用于提供输入值给内核函数。常量变量的值不能被内核函数代码更改。常量变量存储在全局内存中，但会被缓存以便高效访问。在适当的访问模式下，访问常量内存非常快且并行。目前，应用程序中常量变量的总大小限制为 65,536 字节。可能需要将输入数据量拆分以适应这一限制。我们将在第 7 章《卷积》中演示常量内存的使用。

一个变量声明之前仅有 `__device__` 关键字（每个 "__" 由两个 "_" 字符组成）的是一个全局变量，将被放置在全局内存中。访问全局变量的速度较慢。访问全局变量的延迟和吞吐量在较新的设备中得到了改进。全局变量的一个重要优点是它们对所有内核的所有线程可见。它们的内容在整个执行过程中也会保持。因此，全局变量可以作为线程跨块协作的手段。然而，需要注意的是，目前没有简单的方法来在不同线程块之间同步或确保全局内存访问中的数据一致性，除非使用原子操作或终止当前的内核执行。因此，全局变量通常用于将信息从一个内核调用传递到另一个内核调用。

在 CUDA 中，指针可以用来指向全局内存中的数据对象。指针在内核和设备函数中有两种典型的使用方式。首先，如果一个对象由主机函数分配，指向该对象的指针由内存分配 API 函数（如 `cudaMalloc`）初始化，并可以作为参数传递给内核函数，如第 2 章《异构数据并行计算》和第 3 章《多维网格与数据》中所示。第二种使用方式是将声明在全局内存中的变量的地址分配给指针变量。例如，内核函数中的语句 `{float* ptr=&GlobalVar;}` 将 `GlobalVar` 的地址分配给自动指针变量 `ptr`。有关如何在其他内存类型中使用指针，请参考 CUDA 编程指南。

## 5.3 瓦片技术以减少内存流量

在 CUDA 中使用设备内存时，我们面临一个内在的权衡：全局内存大但速度慢，而共享内存小但速度快。一个常见的策略是将数据划分为称为“瓦片”的子集，使每个瓦片可以适应共享内存。瓦片这个术语源于这样一个类比：一个大墙（即全局内存数据）可以被小瓦片（即每个可以适应共享内存的子集）覆盖。一个重要的标准是这些瓦片上的内核计算可以相互独立地进行。需要注意的是，并不是所有数据结构都可以根据任意内核函数被划分为瓦片。

通过第 3 章《多维网格与数据》中的矩阵乘法示例可以说明瓦片的概念。图 3.13 显示了一个小的矩阵乘法示例。它对应于图 3.11 中的内核函数。为了方便参考，我们在图 5.5 中复制了这个示例。为了简洁起见，我们将 `P[y*Width+x]`、`M[y*Width+x]` 和 `N[y*Width+x]` 简写为 P<sub>y,x</sub>、M<sub>y,x</sub> 和 N<sub>y,x</sub>。这个示例假设我们使用 4*2 的块来计算 P 矩阵。P 矩阵中的重框定义了每个块处理的 P 元素。图 5.5 突出了块 <sub>0,0</sub> 的四个线程所做的计算。这四个线程计算 P<sub>0,0</sub>、P<sub>0,1</sub>、P<sub>1,0</sub> 和 P<sub>1,1</sub>。线程 <sub>0,0</sub> 和线程 <sub>0,1</sub> 访问 M 和 N 元素的操作用黑色箭头突出显示。例如，线程 <sub>0,0</sub> 读取 M<sub>0,0</sub> 和 N<sub>0,0</sub>，接着是M<sub>0,1</sub> 和 N<sub>1,0</sub>，然后是 M<sub>0,2</sub> 和 N<sub>2,0</sub>，最后是 M<sub>0,3</sub> 和 N<sub>3,0</sub>。图 5.6 显示了块 <sub>0,0</sub> 中所有线程执行的全局内存访问。

![image](https://github.com/user-attachments/assets/81c68995-49ef-42f1-b531-54bb305c674c)
> FIGURE 5.5 矩阵乘法的小示例。为了简洁，我们将 `M[y*Width+x]`、`N[y*Width+x]` 和 `P[y*Width+x]` 显示为 M<sub>y,x</sub>、N<sub>y,x</sub> 和 P<sub>y,x</sub>。

![image](https://github.com/user-attachments/assets/0ab45d48-7bd1-44b7-8964-78e96b25dfbb)
> FIGURE 5.6 块 <sub>0,0</sub> 中线程执行的全局内存访问。

线程按垂直方向列出，访问时间从左到右增加。请注意，每个线程在执行期间访问了四个 M 元素和四个 N 元素。在这四个线程中，它们访问的 M 和 N 元素之间存在显著的重叠。例如，线程 <sub>0,0</sub> 和线程 <sub>0,1</sub> 都访问了 M<sub>0,0</sub> 以及 M 的第 0 行的其余部分。同样，线程 <sub>0,1</sub> 和线程 <sub>1,1</sub> 都访问了 N<sub>0,1</sub> 以及 N 的第 1 列的其余部分。

图 3.11 中的内核被编写成使线程 <sub>0,0</sub> 和线程 <sub>0,1</sub> 从全局内存中访问 M 的第 0 行元素。如果我们可以设法让线程 <sub>0,0</sub> 和线程 <sub>0,1</sub> 协作，使这些 M 元素仅从全局内存中加载一次，我们可以将全局内存访问的总数减少一半。事实上，我们可以看到每个 M 和 N 元素在块 <sub>0,0</sub> 执行期间被访问了两次。因此，如果我们可以让所有四个线程在对全局内存的访问中进行协作，我们可以将对全局内存的流量减少一半。

读者应该验证，在矩阵乘法示例中，全局内存流量的潜在减少与使用的块的维度成正比。使用 `Width*Width` 块时，全局内存流量的潜在减少将是 `Width`。也就是说，如果我们使用 16*16 的块，我们可以通过线程之间的协作将全局内存流量减少到原始水平的 1/16。

我们现在介绍一个瓦片矩阵乘法算法。基本思想是让线程协作地将 M 和 N 元素的子集加载到共享内存中，然后每个线程在计算其点积时单独使用这些元素。请记住，共享内存的大小相当小，因此在将 M 和 N 元素加载到共享内存时，必须小心不要超过共享内存的容量。这可以通过将 M 和 N 矩阵划分为更小的瓦片来实现。这些瓦片的大小选择使它们可以适应共享内存。在最简单的形式中，瓦片的维度等于块的维度，如图 5.7 所示。

![image](https://github.com/user-attachments/assets/4e02e83a-9c6a-49ec-85d8-935b3442a7c2)
> FIGURE 5.7 划分 M 和 N 以利用共享内存。

![image](https://github.com/user-attachments/assets/4168c732-33e8-42c8-baf6-681314230c79)
> FIGURE 5.8 瓦片矩阵乘法的执行阶段。

在图 5.7 中，我们将 M 和 N 划分为 2*2 的瓦片，如粗线所示。每个线程执行的点积计算现在被分为几个阶段。在每个阶段，块中的所有线程协作将一个 M 瓦片和一个 N 瓦片加载到共享内存中。这可以通过让块中的每个线程将一个 M 元素和一个 N 元素加载到共享内存中来实现，如图 5.8 所示。图 5.8 的每一行显示了一个线程的执行活动。注意时间从左到右推进。我们只需显示块 <sub>0,0</sub> 中线程的活动；其他块具有相同的行为。M 元素的共享内存数组称为 Mds。N 元素的共享内存数组称为 Nds。在第 1 阶段开始时，块 <sub>0,0</sub> 的四个线程协作将 M 的一个瓦片加载到共享内存中：线程 <sub>0,0</sub> 将 M<sub>0,0</sub> 加载到 Mds<sub>0,0</sub> 中，线程 <sub>0,1</sub> 将 M<sub>0,1</sub> 加载到 Mds<sub>0,1</sub> 中，线程 <sub>1,0</sub> 将 M<sub>1,0</sub> 加载到 Mds<sub>1,0</sub> 中，线程 <sub>1,1</sub> 将 M<sub>1,1</sub> 加载到 Mds<sub>1,1</sub> 中。这些加载操作显示在图 5.8 的第二列。N 的一个瓦片也以类似的方式加载，如图 5.8 的第三列所示。

在两个 M 和 N 瓦片加载到共享内存后，这些元素将在点积计算中使用。请注意，共享内存中的每个值被使用了两次。例如，由线程 <sub>1,1</sub> 加载到 Mds<sub>1,1</sub> 的 M<sub>1,1</sub> 值被线程 <sub>1,0</sub> 和线程 <sub>1,1</sub> 各使用一次。通过将每个全局内存值加载到共享内存中，使其可以被多次使用，我们减少了对全局内存的访问次数。在这种情况下，我们将对全局内存的访问次数减少了 2 倍。读者应该验证，如果瓦片是 `N*N` 元素，则减少的倍数为 N。

请注意，每个点积的计算现在分为两个阶段，如图 5.8 中的阶段 1 和阶段 2 所示。在每个阶段，每个线程将输入矩阵元素的两个对的乘积累加到 `Pvalue` 变量中。请注意，`Pvalue` 是一个自动变量，因此为每个线程生成了一个私有版本。我们添加了下标

以澄清这些是为每个线程创建的不同 `Pvalue` 变量实例。第一个阶段的计算显示在图 5.8 的第四列，第二个阶段显示在第七列。

一般来说，如果输入矩阵的维度是 Width，且瓦片大小为 `TILE_WIDTH`，则点积计算将分为 `Width/TILE_WIDTH` 个阶段。

这些阶段的创建是减少对全局内存访问的关键。每个阶段关注输入矩阵值的小子集，线程可以协作地将子集加载到共享内存中，并使用共享内存中的值来满足它们在该阶段的重叠输入需求。

还要注意，Mds 和 Nds 在各阶段之间被重复使用。在每个阶段，相同的 Mds 和 Nds 被重复使用来存放该阶段使用的 M 和 N 元素的子集。这允许更小的共享内存服务于大多数全局内存访问。这是因为每个阶段关注输入矩阵元素的小子集。这种集中访问行为称为局部性。当算法表现出局部性时，有机会使用小的高速内存来服务大多数访问，并将这些访问从全局内存中移除。局部性对于实现多核 CPU 和许多线程 GPU 的高性能同样重要。我们将在第 6 章《性能考虑》中回到局部性概念。

## 5.4 瓦片矩阵乘法内核

```cuda
#define TILE_WIDTH 16
__global__ void matrixMulKernel(float* M, float* N, float* P, int Width){
    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];
    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];

    int bx = blockIdx.x; int by = blockIdx.y;
    int tx = threadIdx.x; int ty = threadIdx.y;

    // 确定要计算的 P 元素的行和列
    int Row = by * TILE_WIDTH + ty;
    int Col = bx * TILE_WIDTH + tx;

    // 遍历计算 P 元素所需的 M 和 N 瓦片
    float Pvalue = 0;
    for (int ph = 0; ph < Width/TILE_WIDTH; ++ph){

        // 协作地将 M 和 N 瓦片加载到共享内存中
        Mds[ty][tx] = M[Row*Width + ph*TILE_WIDTH + tx];
        Nds[ty][tx] = N[(ph*TILE_WIDTH + ty)*Width + Col];
        __syncthreads();

        for (int k = 0; k < TILE_WIDTH; ++k){
            Pvalue += Mds[ty][k] * Nds[k][tx];
        }
        __syncthreads();
    }
    P[Row*Width + Col] = Pvalue;
}
```
> FIGURE 5.9 使用共享内存的瓦片矩阵乘法内核。

我们现在可以展示一个使用共享内存来减少对全局内存访问的瓦片矩阵乘法内核。图 5.9 中的内核实现了图 5.8 中的各个阶段。在图 5.9 中，第 04 和第 05 行分别声明了 `Mds` 和 `Nds` 为共享内存数组。请记住，共享内存变量的作用域是一个块。因此，每个块将创建一个 `Mds` 和 `Nds` 数组的版本，并且块中的所有线程都可以访问相同的 `Mds` 和 `Nds` 版本。这很重要，因为块中的所有线程必须访问由它们的同伴加载到 `Mds` 和 `Nds` 中的 M 和 N 元素，以便它们可以使用这些值来满足它们的输入需求。

第 07 和第 08 行将 `threadIdx` 和 `blockIdx` 的值保存到短名称的自动变量中，以使代码更加简洁。请记住，自动标量变量被放入寄存器中。它们的作用域在每个线程中。也就是说，运行时系统为每个线程创建了一个私有版本的 `tx`、`ty`、`bx` 和 `by`，并将其存储在线程可以访问的寄存器中。这些变量被初始化为 `threadIdx` 和 `blockIdx` 的值，并在线程的生命周期内多次使用。一旦线程结束，这些变量的值就会消失。

第 11 和第 12 行分别确定了线程要生成的 P 元素的行索引和列索引。代码假设每个线程负责计算一个 P 元素。如第 12 行所示，线程生成的 P 元素的水平（x）位置或列索引可以计算为 `bx*TILE_WIDTH+tx`。这是因为每个块在水平维度上覆盖了 `TILE_WIDTH` 个 P 元素。块 `bx` 中的一个线程之前会有 `bx` 个线程块，即 (`bx*TILE_WIDTH`) 个线程，它们覆盖了 `bx*TILE_WIDTH` 个 P 元素。同样，块中的另一个 `tx` 线程会覆盖 `tx` 个其他元素。因此，具有 `bx` 和 `tx` 的线程应负责计算其 x 索引为 `bx*TILE_WIDTH+tx` 的 P 元素。例如，在图 5.7 中，块 `<sub>1,0</sub>` 中线程 `<sub>0,1</sub>` 计算的 P 元素的水平（x）索引是 0*2+1=1。这个水平索引保存在线程的变量 `Col` 中，并且在图 5.10 中也有所说明。

![image](https://github.com/user-attachments/assets/0b18bfe3-731a-497c-aa5a-972d5da12cfe)
> FIGURE 5.10 瓦片乘法中的矩阵索引计算。

类似地，线程处理的 P 元素的垂直（y）位置或行索引计算为 `by*TILE_WIDTH+ty`。回到图 5.7 的示例，块 `<sub>1,0</sub>` 中线程 `<sub>0,1</sub>` 计算的 P 元素的 y 索引是 1*2+0=2。这个垂直索引保存在线程的变量 `Row` 中。如图 5.10 所示，每个线程计算位于 `Col` 列和 `Row` 行的 P 元素。因此，块 `<sub>1,0</sub>` 中线程 `<sub>0,1</sub>` 计算的 P 元素是 `P<sub>2,1</sub>`。

图 5.9 的第 16 行标志着循环的开始，该循环遍历计算 P 元素的所有阶段。循环的每次迭代对应于图 5.8 中显示的一个计算阶段。`ph` 变量表示点积计算中已经完成的阶段数。请记住，每个阶段使用一个 M 瓦片和一个 N 瓦片。因此，在每个阶段开始时，`ph*TILE_WIDTH` 对 M 和 N 元素的配对已经由之前的阶段处理过。

在每个阶段中，图 5.9 的第 19 和第 20 行分别将适当的 M 和 N 元素加载到共享内存中。由于我们已经知道线程要处理的 M 的行和 N 的列，现在我们关注 M 的列索引和 N 的行索引。如图 5.10 所示，每个块有 `TILE_WIDTH<sup>2</sup>` 个线程，将协作加载 `TILE_WIDTH<sup>2</sup>` 个 M 元素和 `TILE_WIDTH<sup>2</sup>` 个 N 元素到共享内存中。因此，我们需要做的就是将每个线程分配一个 M 元素和一个 N 元素。通过使用 `blockIdx` 和 `threadIdx` 可以方便地完成这个任务。请注意，加载的 M 元素的部分的起始列索引是 `ph*TILE_WIDTH`。因此，一个简单的方法是让每个线程加载与起始点相距 `tx`（即 `threadIdx.x` 值）的位置的元素。类似地，加载的 N 元素的部分的起始行索引也是 `ph*TILE_WIDTH`。因此，每个线程加载与起始点相距 `ty`（即 `threadIdx.y` 值）的位置的元素。

这正是第 19 和第 20 行所做的。在第 19 行，每个线程加载 `M[Row*Width + ph*TILE_WIDTH + tx]`，其中线性索引由行索引 `Row` 和列索引 `ph*TILE_WIDTH + tx` 形成。由于 `Row` 的值是 `ty` 的线性函数，因此 `TILE_WIDTH<sup>2</sup>` 个线程将每个线程加载到共享内存中的 M 元素是唯一的，因为每个线程具有唯一的 `tx` 和 `ty` 组合。一起，这些线程将加载图 5.10 中 M 的一个深色方块子集。类似地，在第 20 行，每个线程使用线性索引 (`ph*TILE_WIDTH + ty)*Width + Col` 将适当的 N 元素加载到共享内存中。读者应使用图 5.7 和图 5.8 中的小示例来验证地址计算是否对个别线程有效。

第 21 行的屏障 `__syncthreads()` 确保所有线程在任何线程可以继续之前，已经完成了将 M 和 N 瓦片加载到 `Mds` 和 `Nds` 中。回顾第 4 章《计算架构与调度》，可以使用 `__syncthreads()` 来使块中的所有线程在任何线程可以继续之前等待彼此到达屏障。这很重要，因为线程使用的 M 和 N 元素可能被其他线程加载。需要确保所有元素在任何线程开始使用这些元素之前已经正确地加载到共享内存中。第 23 行的循环基于瓦片元素执行一个点积计算阶段。线程 `<sub>ty, tx</sub>` 的循环进度显示在图 5.10 中，M 和 N 元素的访问方向沿着箭头标记为 k，即第 23 行中的循环变量。请注意，这些元素将从 `Mds` 和 `Nds` 共享内存数组中访问，这些数组存储这些 M 和 N 元素。第 26 行的屏障 `__syncthreads()` 确保所有线程在任何线程开始下一次迭代并加载下一个瓦片的元素之前，已经完成了对共享内存中 M 和 N 元素的使用。因此，没有线程会过早地加载元素，从而破坏其他线程的输入值。

第 21 行和第 26 行的两个 `__syncthreads()` 调用演示了并行程序员在协调线程之间时常常需要考虑的两种数据依赖性。第一个称为读后写依赖性，因为线程必须等待其他线程将数据写入适当的位置，然后才能尝试读取它。第二个称为写后读依赖性，因为线程必须等待所有需要数据的线程读取数据后才能覆盖它。读后写和写后读依赖性的其他名称分别是真依赖性和假依赖性。读后写依赖性是真依赖性，因为读取线程确实需要写入线程提供的数据，所以它别无选择，只能等待。写后读依赖性是假依赖性，因为写入线程不需要读取线程的数据。依赖性是由它们重复使用相同的内存位置引起的，如果它们使用不同的位置，则不会存在这种依赖性。

第 16 行到第 28 行的循环嵌套演示了一种称为带状划分的技术，该技术将一个长期运行的循环分解为多个阶段。每个阶段涉及一个内循环，该内循环执行原始循环的几个连续迭代。原始循环变成一个外循环，其作用是迭代地调用内循环，以便按原始顺序执行原始循环的所有迭代。通过在内循环之前和之后添加屏障同步，我们强制同一块中的所有线程在每个阶段专注于相同的输入数据部分。带状划分是创建数据并行程序中所需阶段的重要手段。

在所有点积计算阶段完成后，执行退出外循环。在第 29 行，所有线程使用从 `Row` 和 `Col` 计算的线性索引写入它们的 P 元素。

瓦片算法的好处是显著的。对于矩阵乘法，全球内存访问减少了 `TILE_WIDTH` 的倍数。使用 16*16 的瓦片，可以将全局内存访问减少 16 倍。这将计算与全局内存访问的比率从 0.25 OP/B 提高到 4 OP/B。这一改进使得 CUDA 设备的内存带宽能够支持更高的计算速率。例如，在具有 1555 GB/秒全局内存带宽的 A100 GPU 中，这一改进使得设备能够实现 (1555 GB/秒)*(4 OP/B)=6220 GFLOPS，这大大高于未使用瓦片的内核所实现的 389 GFLOPS。

尽管瓦片提高了吞吐量，但 6220 GFLOPS 仍然仅为设备 19,500 GFLOPS 峰值吞吐量的 32%。可以进一步优化代码以减少全局内存访问并提高吞吐量。我们将在本书的后面部分看到一些这些优化，而其他高级优化将不会被涵盖。由于矩阵乘法在许多领域的重要性，已经有许多高度优化的库，如 `cuBLAS` 和 `CUTLASS`，它们已经包含了许多这些高级优化。程序员可以使用这些库来立即在其线性代数应用程序中接近峰值性能。

瓦片在提高矩阵乘法以及应用程序的一般吞吐量方面的有效性并不仅仅局限于 GPU。将瓦片（或块）技术应用于提高 CPU 性能的历史悠久，通过确保 CPU 线程在特定时间窗口内重用的数据将会在缓存中找到。一个关键的区别是，CPU 上的瓦片技术依赖于 CPU 缓存隐式地将重用的数据保留在芯片上，而 GPU 上的瓦片技术则明确地使用共享内存来将数据保留在芯片上。原因在于 CPU 核心通常一次运行一个或两个线程，因此线程可以依赖缓存保持最近使用的数据。相比之下，GPU SM 同时运行多个线程以隐藏延迟。这些线程可能会争夺缓存槽，这使得 GPU 缓存不那么可靠，因此需要使用共享内存来存储需要重用的重要数据。

尽管带状矩阵乘法内核的性能提升令人印象深刻，但它确实做出了一些简化假设。首先，假设矩阵的宽度是线程块宽度的倍数。这会阻止内核正确处理宽度为任意值的矩阵。第二个假设是矩阵是方形矩阵。这在实践中并不总是如此。在下一节中，我们将展示一个带有边界检查的内核，以去除这些假设。

## 5.5 边界检查

我们现在将瓦片矩阵乘法内核扩展到处理任意宽度的矩阵。这些扩展将允许内核正确处理宽度不是瓦片宽度倍数的矩阵。让我们将图 5.7 中的小示例更改为使用 3x3 的 M、N 和 P 矩阵。修订后的示例如图 5.11 所示。注意，矩阵的宽度为 3，这不是瓦片宽度（2）的倍数。图 5.11 显示了块 `<sub>0,0</sub>` 第二阶段的内存访问模式。我们可以看到，线程 <sub>0,1</sub> 和线程 <sub>1,1</sub> 将尝试加载不存在的 M 元素。同样，我们也看到线程 <sub>1,0</sub> 和线程 <sub>1,1</sub> 将尝试访问不存在的 N 元素。

![image](https://github.com/user-attachments/assets/d393a56b-506a-41ec-a907-2dc004b19b2a)
> 图 5.11 加载接近边缘的输入矩阵元素：块 <sub>0,0</sub> 的阶段。

访问不存在的元素存在两种问题。首先，访问超出行末尾的不存在元素（图 5.11 中线程 <sub>0,1</sub> 和线程 <sub>1,1</sub> 的 M 访问）会导致这些访问错误地访问了不正确的元素。在我们的示例中，这些线程会尝试访问 M<sub>0,3</sub> 和 M<sub>1,3</sub>，这些元素并不存在。那么这些内存加载会发生什么？为了回答这个问题，我们需要回到二维矩阵的线性化布局。

在线性化布局中，M<sub>0,2</sub> 后面的元素是 M<sub>1,0</sub>。虽然线程 <sub>0,1</sub> 正在尝试访问 M<sub>0,3</sub>，但它最终会得到 M<sub>1,0</sub>。在随后的内积计算中使用这个值显然会破坏输出值。

在访问超出列末尾的元素时也会出现类似的问题（图 5.11 中线程 <sub>1,0</sub> 和线程 <sub>1,1</sub> 的 N 访问）。这些访问指向数组分配区域之外的内存位置。在某些系统中，它们会返回来自其他数据结构的随机值。在其他系统中，这些访问会被拒绝，导致程序中断。无论哪种情况，这种访问的结果都是不可取的。

从我们到目前为止的讨论来看，可能会觉得问题访问仅出现在线程执行的最后阶段。这表明我们可以通过在瓦片内核执行的最后阶段采取特别措施来处理这个问题。不幸的是，事实并非如此。问题访问可以出现在所有阶段。图 5.12 显示了块 <sub>1,1</sub> 在阶段 0 的内存访问模式。我们看到线程 <sub>1,0</sub> 和线程 <sub>1,1</sub> 尝试访问不存在的 M 元素 M<sub>3,0</sub> 和 M<sub>3,1</sub>，而线程 <sub>0,1</sub> 和线程 <sub>1,1</sub> 尝试访问不存在的 N 元素 N<sub>0,3</sub> 和 N<sub>1,3</sub>。

![image](https://github.com/user-attachments/assets/d910e62e-dde2-471c-b8ac-c49bf63cce49)
> 图 5.12 在块 <sub>1,1</sub> 的阶段 0 中加载输入元素。

注意，这些问题访问不能仅通过排除不计算有效 P 元素的线程来避免。例如，块 <sub>1,1</sub> 中的线程 <sub>1,0</sub> 不计算任何有效的 P 元素。然而，它需要在阶段 0 中加载 M<sub>2,1</sub> 以供块 <sub>1,1</sub> 中的其他线程使用。此外，注意到一些计算有效 P 元素的线程会尝试访问不存在的 M 或 N 元素。例如，如图 5.11 所示，块 <sub>0,0</sub> 中的线程 <sub>0,1</sub> 计算了一个有效的 P 元素 P<sub>0,1</sub>。然而，它在阶段 1 中尝试访问不存在的 M<sub>0,3</sub>。这两个事实表明，我们需要对加载 M 瓦片、加载 N 瓦片以及计算/存储 P 元素使用不同的边界条件测试。一个经验法则是，每个内存访问都需要有一个相应的检查，以确保访问中使用的索引在被访问的数组的边界内。

让我们从加载输入瓦片的边界测试条件开始。当一个线程要加载一个输入瓦片元素时，它应该测试要加载的输入元素是否有效。这可以通过检查 y 和 x 索引来轻松完成。例如，在图 5.9 的第 19 行中，线性索引是由行索引 `Row` 和 x 索引 `ph*TILE_WIDTH+tx` 计算得出的。边界条件测试是：两个索引都小于 `Width`：`Row < Width && (ph*TILE_WIDTH+tx) < Width`。如果条件为真，线程应该继续加载 M 元素。读者应验证加载 N 元素的条件测试是 `(ph*TILE_WIDTH+ty) < Width && Col < Width`。

如果条件为假，线程不应加载该元素。问题是应该在共享内存位置放置什么。答案是 0.0，这是一个在内积计算中使用不会造成任何危害的值。如果任何线程在其内积计算中使用这个 0.0 值，内积值将不会发生变化。

最后，线程应该仅在负责计算有效 P 元素时才存储其最终的内积值。对此条件的测试是 `(Row < Width) && (Col < Width)`。具有附加边界条件检查的内核代码如图 5.13 所示。

```cuda
// 遍历计算 P 元素所需的 M 和 N 瓦片
float Pvalue = 0;
for (int ph; ph < ceil(Width/(float)TILE_WIDTH); ++ph){
  // 协作地将 M 和 N 瓦片加载到共享内存中
  if ((Row < Width) && (ph*TILE_WIDTH+tx) < Width){
    Mds[ty][tx] = M[Row*TILE_WIDTH + ph*TILE_WIDTH + tx];
    }
  else Mds[ty][tx] = 0.0f;
  if ((ph*TILE_WIDTH+ty) < Width && Col < Width){
    Nds[ty][tx] = N[(ph*TILE_WIDTH + ty)*Width + Col];
  else Nds[ty][tx] = 0.0f;
  __syncthreads();
  }

  for (int k = 0; k < TILE_WIDTH; ++k){
    Pvalue += Mds[ty][k] * Nds[k][tx];
  }
  __syncthreads();
}
if (Row < Width) && (Col < Width){
  P[Row*Width + Col] = Pvalue};
```
> 图 5.13 带有边界条件检查的瓦片矩阵乘法内核。

通过边界条件检查，瓦片矩阵乘法内核只差一步就成为通用矩阵乘法内核。一般来说，矩阵乘法定义为矩形矩阵：一个 j×k 的 M 矩阵乘以一个 k×l 的 N 矩阵会得到一个 j×l 的 P 矩阵。我们的内核目前只能处理方形矩阵。


幸运的是，将我们的内核进一步扩展为通用矩阵乘法内核非常简单。我们需要做一些简单的更改。首先，将 `Width` 参数替换为三个无符号整数参数：`j`、`k` 和 `l`。其中，`Width` 用于表示 M 的高度或 P 的高度时，用 `j` 替换它；`Width` 用于表示 M 的宽度或 N 的高度时，用 `k` 替换它；`Width` 用于表示 N 的宽度或 P 的宽度时，用 `l` 替换它。具有这些更改的内核修订留作练习。

## 5.6 内存使用对占用率的影响

回顾一下，在第4章《计算架构与调度》中，我们讨论了最大化线程在 SM（流处理器）上的占用率的重要性，以便能够容忍长延迟操作。内核的内存使用在占用率调整中扮演着重要角色。虽然 CUDA 寄存器和共享内存可以极大地减少对全局内存的访问次数，但必须小心地保持在 SM 的这些内存的容量范围内。每个 CUDA 设备提供有限的资源，这限制了在给定应用中可以同时驻留在 SM 中的线程数量。一般来说，每个线程所需的资源越多，能够驻留在每个 SM 中的线程数量就越少。

我们在第4章《计算架构与调度》中看到，寄存器使用可能是占用率的限制因素。共享内存使用也可能限制每个 SM 可以分配的线程数量。例如，A100 GPU 可以配置为每个 SM 具有最多 164 KB 的共享内存，并支持每个 SM 最多 2048 个线程。因此，为了使用所有 2048 个线程槽，线程块每个线程使用的共享内存平均值不应超过 (164 KB)/(2048 线程) = 82 B/线程。在瓦片矩阵乘法示例中，每个块有 `TILE_WIDTH<sup>2</sup>` 个线程，并为 Mds 使用了 `TILE_WIDTH`<sup>2</sup>*4B 的共享内存，为 Nds 使用了 `TILE_WIDTH`<sup>2</sup>*4B 的共享内存。因此，线程块的共享内存平均使用量是 (`TILE_WIDTH`<sup>2</sup>*4B + `TILE_WIDTH`<sup>2</sup>*4B)/(`TILE_WIDTH`<sup>2</sup> 线程) = 8 B/线程。因此，瓦片矩阵乘法内核的占用率不会受到共享内存的限制。

然而，考虑一个内核，其中线程块使用 32 KB 的共享内存，每个线程块有 256 个线程。在这种情况下，内核使用了 (32 KB)/(256 线程) = 132 B/线程 的共享内存。使用这样的共享内存，内核无法实现完全占用率。每个 SM 最大只能容纳 (164 KB)/(132 B/线程) = 1272 个线程。因此，该内核的最大可实现占用率将是 (1272 分配线程)/(2048 最大线程) = 62%。

请注意，每个 SM 中的共享内存大小也可能因设备而异。每一代或型号的设备在每个 SM 中的共享内存量可能不同。通常，内核能够根据硬件中可用的共享内存量使用不同量的共享内存是很有益的。也就是说，我们可能希望主机代码动态确定共享内存的大小，并调整内核使用的共享内存量。这可以通过调用 `cudaGetDeviceProperties` 函数来完成。假设将变量 `&devProp` 传递给该函数。在这种情况下，字段 `devProp.sharedMemPerBlock` 给出了每个 SM 中可用的共享内存量。然后，程序员可以确定每个块应使用多少共享内存。

不幸的是，图 5.9 和图 5.13 中的内核不支持主机代码对共享内存使用的动态调整。图 5.9 中使用的声明将其共享内存使用大小硬编码为编译时常量：

```cuda
__shared__ float Mds[TILE_WIDTH][TILE_WIDTH];
__shared__ float Nds[TILE_WIDTH][TILE_WIDTH];
```

也就是说，`Mds` 和 `Nds` 的大小设置为 `TILE_WIDTH`<sup>2</sup> 个元素，无论编译时 `TILE_WIDTH` 的值是多少。由于代码中包含 `#define TILE_WIDTH 16`，因此 `Mds` 和 `Nds` 将有 256 个元素。如果我们想改变 `Mds` 和 `Nds` 的大小，我们需要更改 `TILE_WIDTH` 的值并重新编译代码。内核无法在运行时轻松调整其共享内存使用，而无需重新编译。

我们可以通过在 CUDA 中使用不同的声明样式来启用这种调整，方法是在共享内存声明前添加 C extern 关键字，并在声明中省略数组的大小。基于这种样式，`Mds` 和 `Nds` 的声明需要合并成一个动态分配的数组：`extern __shared__ float Mds_Nds[];`

由于只有一个合并数组，我们还需要手动定义 `Mds` 部分和 `Nds` 部分的数组起始位置。注意，合并的数组是一维的。我们需要使用基于垂直和水平索引的线性化索引来访问它。

在运行时，当我们调用内核时，可以根据设备查询结果动态配置每个块将使用的共享内存量，并将其作为内核调用的第三个配置参数提供。例如，修订后的内核可以用以下语句启动：

```cuda
size_t size = calculate_appropriate_SM_usage(devProp.sharedMemPerBlock, ...);

matrixMulKernel<<<dimGrid, dimBlock, size>>>(Md, Nd, Pd, Width, size/2, size/2);
```

其中 `size_t` 是一个用于声明变量以存储动态分配数据结构大小信息的内置类型。大小以字节为单位表示。在我们的矩阵乘法示例中，对于一个 16x16 的瓦片，我们需要的大小是 2*16*16*4=2048 字节，以容纳 `Mds` 和 `Nds`。我们省略了计算运行时设置 `size` 值的详细信息，留作读者练习。

在图 5.14 中，我们展示了如何修改图 5.9 和图 5.11 中的内核代码，以便为 `Mds` 和 `Nds` 数组使用动态大小的共享内存。在这个示例中，我们还添加了两个参数：第一个参数是 `Mds` 部分的大小，第二个参数是 `Nds` 部分的大小，单位为字节。注意，在上面的主机代码中，我们传递了 size/2 作为这些参数的值，即 1024 字节。通过第 06 行和第 07 行的赋值，其余的内核代码可以将 `Mds` 和 `Nds` 作为数组的基址，并使用线性化索引访问 `Mds` 和 `Nds` 元素。例如，可以使用 `Mds[ty*TILE_WIDTH+tx]` 代替 `Mds[ty][tx]`。

```cuda
# define TILE_WIDTH 16
__global__ void matrixMulKernel(float* M, float* N, float* P, int Width,
                                  unsigned Mds_sz, unsigned Nds_sz){
    extern __shared__ char Mds_Nds[];
    float *Mds = (float *) Mds_Nds;
    float *Nds = (float *) Mds_Nds + Mds_sz;
}
```
> 图 5.14 带有动态大小共享内存使用的瓦片矩阵乘法内核。

## 5.7 总结

总之，现代处理器中程序的执行速度可能会受到内存速度的严重限制。为了实现 CUDA 设备执行吞吐量的良好利用，需要在内核代码中追求高的计算与全局内存访问比。如果比率低，内核是内存绑定的。也就是说，其执行速度受到从内存中访问操作数的速率的限制。

CUDA 提供了对寄存器、共享内存和常量内存的访问。这些内存比全局内存小得多，但可以以更高的速度访问。有效地使用这些内存需要重新设计算法。我们以矩阵乘法为例，展示了瓦片技术，这是一种流行的策略，可以增强数据访问的局部性，并实现对共享内存的有效利用。在并行编程中，瓦片技术利用屏障同步强制多个线程在每个执行阶段共同关注输入数据的一个子集，以便将这些子集数据放入这些特殊的内存类型中，从而实现更高的访问速度。

然而，CUDA 程序员需要意识到这些特殊类型内存的有限大小。它们的容量是实现依赖的。一旦超出其容量，它们会限制每个 SM 中可以同时执行的线程数量，并可能对 GPU 的计算吞吐量及其容忍延迟的能力产生负面影响。在开发应用程序时能够理解硬件限制是并行编程的一个关键方面。

虽然我们在 CUDA C 编程的背景下介绍了瓦片算法，但它是一种在几乎所有类型的并行计算系统中实现高性能的有效策略。原因是，应用程序必须在数据访问中表现出局部性，以有效利用这些系统中的高速内存。例如，在多核 CPU 系统中，数据局部性允许应用程序有效使用片上数据缓存，以减少内存访问延迟并实现高性能。这些片上数据

缓存的大小也有限，并且需要计算展示局部性。因此，读者在为其他类型的并行计算系统使用其他编程模型开发并行应用程序时，也会发现瓦片算法是有用的。

我们本章的目标是介绍局部性、瓦片技术和不同的 CUDA 内存类型。我们介绍了使用共享内存的瓦片矩阵乘法内核。我们进一步研究了边界测试条件的需要，以允许在应用瓦片技术时支持任意数据维度。我们还简要讨论了动态大小共享内存分配的使用，以便内核可以根据硬件能力调整每个块使用的共享内存大小。我们没有讨论寄存器在瓦片技术中的使用。我们将在本书第二部分讨论并行算法模式时解释寄存器在瓦片算法中的使用。
