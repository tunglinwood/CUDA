# 5_内存架构与数据局部性

* 5.1 [内存访问效率的重要性]
* 5.2 [CUDA 内存类型]
* 5.3 [通过分块减少内存流量]
* 5.4 [分块矩阵乘法内核]
* 5.5 [边界检查]
* 5.6 [内存使用对占用率的影响]
* 5.7 [总结]
* [练习题]

到目前为止，我们已经学习了如何编写 CUDA 内核函数，以及如何配置和协调大量线程的执行。我们还研究了当前 GPU 硬件的计算架构，以及线程如何在这些硬件上调度执行。本章我们将重点讨论 GPU 的片上内存架构，并开始研究如何组织和定位数据以便大量线程高效访问。我们迄今为止研究的 CUDA 内核可能只实现了底层硬件潜在速度的一小部分。这种性能差是因为全局内存（通常用片外 DRAM 实现）往往有很长的访问延迟（数百个时钟周期）和有限的访问带宽。虽然可用的线程数量很多理论上可以容忍长时间的内存访问延迟，但很容易遇到全局内存访问路径中的流量拥塞，阻止大部分线程进展，从而使流处理多处理器（SMs）中的一些核心处于空闲状态。为了规避这种拥塞，GPU 提供了许多额外的片上内存资源用于访问数据，从而减少与全局内存之间的大部分流量。本章我们将研究使用不同的内存类型来提升 CUDA 内核的执行性能。

## 5.1 内存访问效率的重要性

我们可以通过计算图 3.11 中矩阵乘法内核代码最常执行部分的预期性能水平来说明内存访问效率的影响，该代码在图 5.1 中部分重复。内核中执行时间最重要的部分是执行 M 行和 N 列点积的 for 循环。

在循环的每次迭代中，为一次浮点乘法和一次浮点加法执行两次全局内存访问。全局内存访问从 M 和 N 数组中获取元素。浮点乘法操作将这两个元素相乘，浮点加法操作将乘积累加到 `Pvalue` 中。因此，浮点操作（FLOP）与全局内存访问的字节数（B）的比率为 2 FLOP 对 8 B，或 0.25 FLOP/B。我们将这种比率称为计算与全局内存访问比率，定义为在程序区域内每访问一个字节的全局内存执行的 FLOP 数。这个比率在文献中有时也被称为算术强度或计算强度。

计算与全局内存访问比率对 CUDA 内核的性能有重大影响。例如，Ampere A100 GPU 的峰值全局内存带宽为 1555 GB/秒。由于矩阵乘法内核执行 0.25 OP/B，全局内存带宽限制了内核每秒可执行的单精度 FLOP 的吞吐量为 389 Giga FLOPs（GFLOPS），通过将 1555 GB/秒乘以 0.25 FLOP/B 得到。然而，389 GFLOPS 仅占 A100 GPU 峰值单精度操作吞吐量 19,500 GFLOPS 的 2%。A100 还配有称为张量核心的专用单元，用于加速矩阵乘法操作。如果考虑 A100 的张量核心峰值单精度浮点吞吐量为 156,000 GFLOPS，389 GFLOPS 仅占峰值的 0.25%。因此，矩阵乘法内核的执行严重受限于数据从内存传送到 GPU 核心的速率。我们将那些执行速度受内存带宽限制的程序称为内存受限程序。

```cuda
for (int k = 0; k < Width; ++k){
	Pvalue += M[row*Width+k] * N[k*Width+col];
}
```

> ### 屋顶线模型
> 屋顶线模型是用于评估应用程序相对于其运行硬件极限的性能的可视模型。屋顶线模型的基本示例如下所示。x 轴上是以 FLOP/B 为单位的算术或计算强度，反映了应用程序每加载一个字节的数据所完成的工作量。y 轴上是以 GFLOPS 为单位的计算吞吐量。图中的两条线反映了硬件的极限。水平线由硬件可以维持的峰值计算吞吐量（GFLOPS）决定。从原点开始的斜线由硬件可以维持的峰值内存带宽决定。图中的一个点表示具有其操作强度的应用程序在 x 轴上的位置以及其在 y 轴上实现的计算吞吐量。显然，这些点会位于两条线以下，因为它们无法实现比硬件峰值更高的吞吐量。
> 点相对于两条线的位置告诉我们应用程序的效率。靠近两条线的点表示应用程序有效地使用了内存带宽或计算单元，而远低于两条线的应用程序则表示资源使用效率低。两条线交点的位置代表应用程序从内存受限转变为计算受限的计算强度值。具有较低计算强度的应用程序是内存受限的，无法实现峰值吞吐量，因为它们受到内存带宽的限制。具有较高计算强度的应用程序是计算受限的，不受内存带宽的限制。
> 例如，点 A1 和 A2 都代表内存受限的应用程序，而 A3 代表计算受限的应用程序。A1 有效地使用了资源，接近峰值内存带宽运行，而 A2 则没有。对于 A2，可能还有优化空间，通过改进内存带宽利用率来提高吞吐量。然而，对于 A1，提高吞吐量的唯一方法是增加应用程序的计算强度。

为了实现此内核的更高性能，我们需要通过减少执行的全局内存访问次数来提高内核的计算与全局内存访问比率。例如，要充分利用 A100 GPU 提供的 19,500 GFLOPS，需要至少达到 (19,500 GOP/秒)/(1555 GB/秒)=12.5 OP/B 的比率。这意味着每访问一个 4 字节的浮点值，需要执行约 50 次浮点操作！能否实现这种比率取决于计算中固有的数据重用程度。我们建议读者参考“屋顶线模型”边栏，该模型是分析程序计算强度相对于其潜在性能的有用模型。

正如我们将看到的，矩阵乘法提供了减少全局内存访问次数的机会，可以通过相对简单的技术实现。矩阵乘法函数的执行速度可能相差几个数量级，具体取决于全局内存访问的减少程度。因此，矩阵乘法是这些技术的一个优秀初始示例。本章介绍了一种常用的减少全局内存访问次数的技术，并演示了该技术在矩阵乘法中的应用。

## 5.2 CUDA 内存类型

CUDA 设备包含多种类型的内存，可以帮助程序员提高计算与全局内存访问比率。图 5.2 显示了这些 CUDA 设备内存。在图的底部，我们看到全局内存和常量内存。这两种类型的内存都可以由主机进行写（W）和读（R）。全局内存也可以由设备进行写和读，而常量内存支持设备的短延迟、高带宽只读访问。我们在第 2 章“异构数据并行计算”中介绍了全局内存，我们将在第 7 章“卷积”中详细介绍常量内存。

> 图 5.2 CUDA 设备内存模型的（不完整）概述。图中未显示的一种重要的 CUDA 内存类型是纹理内存，因为本教材不涉及其使用。

另一种内存类型是局部内存，也可以进行读写。局部内存实际上位于全局内存中，具有类似的访问延迟，但不在线程之间共享。每个线程都有自己的一部分全局内存，作为其私有局部内存，用于存放私有数据，但不能在寄存器中分配。这些数据包括静态分配的数组、溢出的寄存器和线程调用栈的其他元素。

图 5.2 中的寄存器和共享内存是片上内存。位于这些类型内存中的变量可以在高度并行的方式下以非常高的速度访问。寄存器分配给各个线程；每个线程只能访问自己的寄存器（参见“CPU 与 GPU 寄存器架构”边栏）。内核函数通常使用寄存器来存储

各线程私有的常访问变量。共享内存分配给线程块；块中的所有线程都可以访问为块声明的共享内存变量。共享内存是线程通过共享其输入数据和中间结果进行合作的有效手段。通过在 CUDA 内存类型之一中声明 CUDA 变量，CUDA 程序员决定了变量的可见性和访问速度。

> ### CPU 与 GPU 寄存器架构
> CPU 和 GPU 之间的不同设计目标导致了不同的寄存器架构。如我们在第 4 章“计算架构与调度”中所见，当 CPU 在不同线程之间进行上下文切换时，它会将退出线程的寄存器保存到内存中，并从内存中恢复进入线程的寄存器。相比之下，GPU 通过在处理块的寄存器文件中保留调度的所有线程的寄存器，实现了零开销调度。这样，线程束之间的切换是瞬时的，因为进入线程的寄存器已经在寄存器文件中。因此，GPU 寄存器文件需要比 CPU 寄存器文件大得多。
>
> 我们还在第 4 章“计算架构与调度”中看到，GPU 支持动态资源分配，其中一个 SM 可能为每个线程提供较少的寄存器并执行大量线程，或者为每个线程提供更多寄存器并执行较少线程。因此，GPU 寄存器文件需要设计为支持这种寄存器的动态分配。相比之下，CPU 寄存器架构为每个线程分配一组固定的寄存器，无论线程的实际寄存器需求如何。

要充分理解寄存器、共享内存和全局内存之间的区别，我们需要详细了解这些不同内存类型在现代处理器中的实现和使用方式。如我们在第 4 章“计算架构与调度”中的“线程束与 SIMD 硬件”边栏中讨论的那样，几乎所有现代处理器都源于 1945 年 John von Neumann 提出的模型，如图 5.3 所示。CUDA 设备也不例外。

> 图 5.3 基于冯·诺依曼模型的现代计算机中的内存与寄存器。

CUDA 设备中的全局内存映射到图 5.3 中的内存框。处理器框对应于我们今天通常看到的处理器芯片边界。全局内存在处理器芯片外，由 DRAM 技术实现，这意味着访问延迟长且访问带宽相对较低。寄存器对应于冯·诺依曼模型中的“寄存器文件”。寄存器文件在处理器芯片上，这意味着访问延迟非常短，访问带宽比全局内存高得多。在典型设备中，所有 SM 的寄存器文件的总访问带宽至少比全局内存高两个数量级。此外，每当变量存储在寄存器中时，其访问不再消耗片外全局内存带宽。这将反映为计算与全局内存访问比率的增加。

更微妙的一点是，每次访问寄存器涉及的指令比访问全局内存的指令少。大多数现代处理器中的算术指令都有“内建”寄存器操作数。例如，浮点加法指令可能是以下形式：

```cuda
fadd r1, r2, r3
```

其中 r2 和 r3 是寄存器号，指定寄存器文件中可以找到输入操作数值的位置。浮点加法结果值的存储位置由 r1 指定。因此，当算术指令的操作数在寄存器中时，不需要额外的指令来使操作数值可用于算术和逻辑单元（ALU），ALU 是执行算术计算的地方。

同时，如果操作数值在全局内存中，处理器需要执行内存加载操作，使操作数值可用于 ALU。例如，如果浮点加法指令的第一个操作数在全局内存中，涉及的指令可能如下所示：

```cuda
load r2, r4, offset
fadd r1, r2, r3
```
其中 `load` 指令将偏移值添加到 r4 的内容中形成操作数值的地址。然后访问全局内存并将值放入寄存器 r2 中。一旦操作数值在 r2 中，`fadd` 指令使用 r2 和 r3 中的值执行浮点加法，并将结果放入 r1 中。由于处理器每个时钟周期只能获取和执行有限数量的指令，因此包含额外加载的版本可能需要更多时间处理。这是将操作数放入寄存器可以提高执行速度的另一个原因。

最后，还有一个更微妙的原因说明将操作数值放入寄存器更优。在现代计算机中，从寄存器文件访问一个值消耗的能量至少比从全局内存访问一个值低一个数量级。从寄存器访问一个值在能效方面比从全局内存访问一个值有巨大优势。我们将在不久的将来看到更多关于现代计算机中访问这些两种硬件结构的速度和能量差异的细节。另一方面，如我们将很快了解到的，现代 GPU 中每个线程可用的寄存器数量相当有限。如我们在第 4 章“计算架构与调度”中所见，如果满占用情况下的寄存器使用超过限制，应用程序的占用率可能会降低。因此，我们还需要尽可能避免过度使用这一有限资源。

图 5.4 显示了 CUDA 设备中的共享内存和寄存器。虽然两者都是片上内存，但在功能和访问成本上有显著差异。共享内存设计为处理器芯片上的内存空间的一部分。当处理器访问位于共享内存中的数据时，需要执行内存加载操作，就像访问全局内存一样。然而，由于共享内存位于芯片上，访问延迟较低，吞吐量远高于全局内存。由于需要执行加载操作，共享内存的延迟比寄存器更长，带宽比寄存器更低。在计算机架构术语中，共享内存是一种形式的临时存储器。
