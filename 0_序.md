# 序

我们很自豪地向您介绍《Programming Massively Parallel Processors: A Hands-on Approach》第四版。

结合了多核CPU和多线程GPU的大众市场计算系统已经将太量级计算带到了笔记本电脑，并将超量级计算带到了集群。拥有这样的计算能力，我们正处于科学、工程、医学和商业领域广泛使用计算实验的黎明。我们还见证了GPU计算在金融、电子商务、石油和天然气、制造业等关键行业垂直市场的广泛应用。这些领域的突破将通过前所未有规模、精度、安全性、可控性和可观察性的计算实验来实现。本书为实现这一愿景提供了关键因素：向数百万研究生和本科生教授并行编程，使计算思维和并行编程技能像微积分技能一样普及。

本书的主要目标读者是所有需要计算思维和并行编程技能以实现突破的科学和工程学科的研究生和本科生。该书还被成功用于需要更新并行计算技能并跟上技术不断进步速度的行业专业开发者。这些专业开发者工作在诸如机器学习、网络安全、自动驾驶、计算金融、数据分析、认知计算、机械工程、土木工程、电气工程、生物工程、物理、化学、天文学和地理等领域，他们使用计算来推动各自领域的发展。因此，这些开发者既是他们所在领域的专家，又是程序员。该书通过建立对技术的直观理解来教授并行编程。我们假设读者至少有一些基本的C语言编程经验。我们使用CUDA C，这是一个支持NVIDIA GPU的并行编程环境。这些处理器在消费者和专业人士手中已经超过10亿，并且有超过40万程序员在积极使用CUDA。作为学习经验的一部分，您开发的应用程序将可以被非常大的用户群体运行。

自2016年第三版出版以来，我们收到了许多来自读者和教师的评论。许多人告诉我们他们重视现有的特性，其他人则给了我们关于如何扩展本书内容以使其更有价值的想法。此外，自2016年以来，异构并行计算的硬件和软件取得了巨大进展。在硬件领域，自第三版以来，已经引入了三个更多的GPU计算架构世代，分别是Volta、Turing和Ampere。

在软件领域，CUDA 9到CUDA 11允许程序员访问新硬件和系统特性。还开发了新的算法。相应地，我们新增了四个章节，并重写了大量现有章节。

新增的四个章节包括一个新的基础章节，即第4章（计算架构和调度），以及三个新的并行模式和应用章节：第8章（模板）、第10章（归约和最小化分歧）和第13章（排序）。我们增加这些章节的动机如下：
- 第4章（计算架构和调度）：在上一版中，架构和调度考虑的讨论分散在多个章节中。在这一版中，第4章将这些讨论整合到一个集中的章节中，为对这个话题特别感兴趣的读者提供了一个集中的参考。
- 第8章（模板）：在上一版中，模板模式在卷积章节中因两者的相似性被简要提及。在这一版中，第8章对模板模式进行了更全面的处理，强调了计算背后的数学背景和使其与卷积不同的方面，从而实现额外的优化。该章节还提供了处理三维网格和数据的示例。
- 第10章（归约和最小化分歧）：在上一版中，归约模式在性能考虑章节中被简要介绍。在这一版中，第10章提供了对归约模式的更完整的介绍，采用增量方法应用优化，并更详细地分析了相关的性能权衡。
- 第13章（排序）：在上一版中，归并排序在归并模式章节中被简要提及。在这一版中，第13章提出了基数排序，这是一种非常适合GPU并行化的非比较排序算法，并采用增量方法对其进行优化并分析性能权衡。本章还讨论了归并排序。

除了新增的章节，所有章节都进行了修订，有些章节进行了大幅重写。这些章节包括：
- 第6章（性能考虑）：某些架构考虑从该章节移到了新第4章，归约示例移到了新第10章。取而代之的是，本章重写了线程粒度考虑，并且更显著的是提供了一个常见性能优化策略和每个策略所解决的性能瓶颈的检查表。这个检查表在教材的其他部分被引用，因为我们优化了实现各种并行模式和应用的代码。目标是强化系统和渐进的方法来优化并行程序的性能。
- 第7章（卷积）：在上一版中，卷积模式章节使用一维卷积作为示例，并在结尾简要处理二维卷积。在这一版中，本章从一开始就更关注二维卷积。这一变化使我们能够处理高维度平铺的复杂性和复杂性，并为读者提供更好的背景以学习第16章中的卷积神经网络。
- 第9章（并行直方图）：在上一版中，直方图模式章节从一开始就应用了线程合并优化，并将私有化优化与使用共享内存结合起来。在这一版中，本章重写了以更渐进的方法进行性能优化。现在展示的初始实现没有应用线程合并。私有化和使用共享内存进行私有分箱被区分为两个独立的优化，前者旨在减少原子操作的争用，后者旨在减少访问延迟。线程合并在私有化后应用，因为合并的一个主要好处是减少提交到公共副本的私有副本数量。新章节的组织更符合全书采用的系统和渐进的性能优化方法。我们还将本章移到了归约和扫描模式章节之前，以便更早引入原子操作，因为它们在多块归约和单次扫描内核中使用。
- 第14章（稀疏矩阵计算）：在这一版中，本章重写了以更系统的方法分析不同稀疏矩阵存储格式之间的权衡。章节开始引入了一个设计稀疏矩阵存储格式时需要考虑的因素列表。然后在全章中使用这一设计考虑列表系统地分析不同格式之间的权衡。
- 第15章（图遍历）：在上一版中，图遍历章节侧重于特定的BFS并行化策略。在这一版中，本章显著扩展了以涵盖更全面的替代并行化策略，并分析了它们之间的权衡。这些策略包括基于顶点的推送、基于顶点的拉取、基于边的以及线性代数实现，除了原始实现，即基于顶点的推送前沿实现。这些替代方案的分类不仅适用于BFS，而且适用于并行化图算法。
- 第16章（深度学习）：在这一版中，本章重写了以提供一个全面但直观的理论背景来理解现代神经网络。该背景使读者更容易全面理解神经网络的计算组件，如全连接层、激活和卷积层。它还消除了一些理解训练卷积神经网络的内核函数的常见障碍。
- 第19章（并行编程和计算思维）：在上一版中，本章讨论了算法选择和问题分解，同时从迭代MRI重建和静电势图的章节中汲取示例。在这一版中，本章修订了以从更多章节中汲取示例，作为第I和第II部分的总结章节。特别扩展了问题分解的讨论，引入了输出中心分解和输入中心分解的一般化，并通过多个示例讨论了它们之间的权衡。
- 第21章（CUDA动态并行）：在上一版中，本章详细介绍了动态并行中的不同编程构造和API调用的语义。在这一版中，本章的重点更多地转向应用示例，其余编程细节简要讨论，并参考有兴趣的读者查阅CUDA编程指南。

<img width="767" alt="image" src="https://github.com/user-attachments/assets/e35b70d6-b122-4383-9cfa-7853209376c4">

在进行所有这些改进时，我们努力保留最受欢迎的特性。首先，我们尽量使解释尽可能直观。虽然形式化某些概念尤其是在介绍基本并行算法时具有诱惑力，但我们努力保持所有解释直观和实用。其次，我们尽量使书籍简洁。虽然增加新材料很有诱惑力，但我们希望尽量减少读者需要学习所有关键概念的页面数量。我们通过将数值考虑章节移至附录实现了这一点。虽然数值考虑是并行计算的一个极其重要的方面，但我们发现章节中的大量内容已经为许多具有计算机科学或计算科学背景的读者所熟知。为此，我们更倾向于将更多的空间用于涵盖额外的并行模式。

除了自上一版以来增加新章节和大幅重写其他章节外，我们还将本书组织为四个主要部分。该组织在图P.1中进行了说明。第一部分介绍了并行编程的基本概念、GPU架构、性能分析和优化。第二部分通过涵盖六种常见的计算模式并展示如何将它们并行化和优化来应用这些概念。每个并行模式还介绍了一种新的编程功能或技术。第三部分介绍了额外的高级模式和应用，并继续应用在第二部分中练习的优化。然而，它更加侧重于探索替代问题分解形式以并行化计算，并分析不同分解及其相关数据结构之间的权衡。最后，第四部分向读者展示高级实践和编程功能。
