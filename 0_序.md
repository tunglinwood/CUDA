# 序

我们很自豪地向您介绍《Programming Massively Parallel Processors: A Hands-on Approach》第四版。

结合了多核CPU和多线程GPU的大众市场计算系统已经将太量级计算带到了笔记本电脑，并将超量级计算带到了集群。拥有这样的计算能力，我们正处于科学、工程、医学和商业领域广泛使用计算实验的黎明。我们还见证了GPU计算在金融、电子商务、石油和天然气、制造业等关键行业垂直市场的广泛应用。这些领域的突破将通过前所未有规模、精度、安全性、可控性和可观察性的计算实验来实现。本书为实现这一愿景提供了关键因素：向数百万研究生和本科生教授并行编程，使计算思维和并行编程技能像微积分技能一样普及。

本书的主要目标读者是所有需要计算思维和并行编程技能以实现突破的科学和工程学科的研究生和本科生。该书还被成功用于需要更新并行计算技能并跟上技术不断进步速度的行业专业开发者。这些专业开发者工作在诸如机器学习、网络安全、自动驾驶、计算金融、数据分析、认知计算、机械工程、土木工程、电气工程、生物工程、物理、化学、天文学和地理等领域，他们使用计算来推动各自领域的发展。因此，这些开发者既是他们所在领域的专家，又是程序员。该书通过建立对技术的直观理解来教授并行编程。我们假设读者至少有一些基本的C语言编程经验。我们使用CUDA C，这是一个支持NVIDIA GPU的并行编程环境。这些处理器在消费者和专业人士手中已经超过10亿，并且有超过40万程序员在积极使用CUDA。作为学习经验的一部分，您开发的应用程序将可以被非常大的用户群体运行。

自2016年第三版出版以来，我们收到了许多来自读者和教师的评论。许多人告诉我们他们重视现有的特性，其他人则给了我们关于如何扩展本书内容以使其更有价值的想法。此外，自2016年以来，异构并行计算的硬件和软件取得了巨大进展。在硬件领域，自第三版以来，已经引入了三个更多的GPU计算架构世代，分别是Volta、Turing和Ampere。

在软件领域，CUDA 9到CUDA 11允许程序员访问新硬件和系统特性。还开发了新的算法。相应地，我们新增了四个章节，并重写了大量现有章节。

新增的四个章节包括一个新的基础章节，即第4章（计算架构和调度），以及三个新的并行模式和应用章节：第8章（模板）、第10章（归约和最小化分歧）和第13章（排序）。我们增加这些章节的动机如下：
- 第4章（计算架构和调度）：在上一版中，架构和调度考虑的讨论分散在多个章节中。在这一版中，第4章将这些讨论整合到一个集中的章节中，为对这个话题特别感兴趣的读者提供了一个集中的参考。
- 第8章（模板）：在上一版中，模板模式在卷积章节中因两者的相似性被简要提及。在这一版中，第8章对模板模式进行了更全面的处理，强调了计算背后的数学背景和使其与卷积不同的方面，从而实现额外的优化。该章节还提供了处理三维网格和数据的示例。
- 第10章（归约和最小化分歧）：在上一版中，归约模式在性能考虑章节中被简要介绍。在这一版中，第10章提供了对归约模式的更完整的介绍，采用增量方法应用优化，并更详细地分析了相关的性能权衡。
- 第13章（排序）：在上一版中，归并排序在归并模式章节中被简要提及。在这一版中，第13章提出了基数排序，这是一种非常适合GPU并行化的非比较排序算法，并采用增量方法对其进行优化并分析性能权衡。本章还讨论了归并排序。

除了新增的章节，所有章节都进行了修订，有些章节进行了大幅重写。这些章节包括：
- 第6章（性能考虑）：某些架构考虑从该章节移到了新第4章，归约示例移到了新第10章。取而代之的是，本章重写了线程粒度考虑，并且更显著的是提供了一个常见性能优化策略和每个策略所解决的性能瓶颈的检查表。这个检查表在教材的其他部分被引用，因为我们优化了实现各种并行模式和应用的代码。目标是强化系统和渐进的方法来优化并行程序的性能。
- 第7章（卷积）：在上一版中，卷积模式章节使用一维卷积作为示例，并在结尾简要处理二维卷积。在这一版中，本章从一开始就更关注二维卷积。这一变化使我们能够处理高维度平铺的复杂性和复杂性，并为读者提供更好的背景以学习第16章中的卷积神经网络。
- 第9章（并行直方图）：在上一版中，直方图模式章节从一开始就应用了线程合并优化，并将私有化优化与使用共享内存结合起来。在这一版中，本章重写了以更渐进的方法进行性能优化。现在展示的初始实现没有应用线程合并。私有化和使用共享内存进行私有分箱被区分为两个独立的优化，前者旨在减少原子操作的争用，后者旨在减少访问延迟。线程合并在私有化后应用，因为合并的一个主要好处是减少提交到公共副本的私有副本数量。新章节的组织更符合全书采用的系统和渐进的性能优化方法。我们还将本章移到了归约和扫描模式章节之前，以便更早引入原子操作，因为它们在多块归约和单次扫描内核中使用。
- 第14章（稀疏矩阵计算）：在这一版中，本章重写了以更系统的方法分析不同稀疏矩阵存储格式之间的权衡。章节开始引入了一个设计稀疏矩阵存储格式时需要考虑的因素列表。然后在全章中使用这一设计考虑列表系统地分析不同格式之间的权衡。
- 第15章（图遍历）：在上一版中，图遍历章节侧重于特定的BFS并行化策略。在这一版中，本章显著扩展了以涵盖更全面的替代并行化策略，并分析了它们之间的权衡。这些策略包括基于顶点的推送、基于顶点的拉取、基于边的以及线性代数实现，除了原始实现，即基于顶点的推送前沿实现。这些替代方案的分类不仅适用于BFS，而且适用于并行化图算法。
- 第16章（深度学习）：在这一版中，本章重写了以提供一个全面但直观的理论背景来理解现代神经网络。该背景使读者更容易全面理解神经网络的计算组件，如全连接层、激活和卷积层。它还消除了一些理解训练卷积神经网络的内核函数的常见障碍。
- 第19章（并行编程和计算思维）：在上一版中，本章讨论了算法选择和问题分解，同时从迭代MRI重建和静电势图的章节中汲取示例。在这一版中，本章修订了以从更多章节中汲取示例，作为第I和第II部分的总结章节。特别扩展了问题分解的讨论，引入了输出中心分解和输入中心分解的一般化，并通过多个示例讨论了它们之间的权衡。
- 第21章（CUDA动态并行）：在上一版中，本章详细介绍了动态并行中的不同编程构造和API调用的语义。在这一版中，本章的重点更多地转向应用示例，其余编程细节简要讨论，并参考有兴趣的读者查阅CUDA编程指南。

<img width="767" alt="image" src="https://github.com/user-attachments/assets/e35b70d6-b122-4383-9cfa-7853209376c4">

在进行所有这些改进时，我们努力保留最受欢迎的特性。首先，我们尽量使解释尽可能直观。虽然形式化某些概念尤其是在介绍基本并行算法时具有诱惑力，但我们努力保持所有解释直观和实用。其次，我们尽量使书籍简洁。虽然增加新材料很有诱惑力，但我们希望尽量减少读者需要学习所有关键概念的页面数量。我们通过将数值考虑章节移至附录实现了这一点。虽然数值考虑是并行计算的一个极其重要的方面，但我们发现章节中的大量内容已经为许多具有计算机科学或计算科学背景的读者所熟知。为此，我们更倾向于将更多的空间用于涵盖额外的并行模式。

除了自上一版以来增加新章节和大幅重写其他章节外，我们还将本书组织为四个主要部分。该组织在图P.1中进行了说明。第一部分介绍了并行编程的基本概念、GPU架构、性能分析和优化。第二部分通过涵盖六种常见的计算模式并展示如何将它们并行化和优化来应用这些概念。每个并行模式还介绍了一种新的编程功能或技术。第三部分介绍了额外的高级模式和应用，并继续应用在第二部分中练习的优化。然而，它更加侧重于探索替代问题分解形式以并行化计算，并分析不同分解及其相关数据结构之间的权衡。最后，第四部分向读者展示高级实践和编程功能。

### 如何使用本书

我们希望提供一些在使用本书教授课程时的经验。自2006年以来，我们教授了多种类型的课程：一个学期的格式和一周的密集格式。最初的ECE498AL课程已成为伊利诺伊大学厄巴纳-香槟分校的ECE408或CS483的永久课程。我们在第二次提供ECE498AL时开始编写本书的一些早期章节。2009年春季，尼古拉斯·平托在麻省理工学院教授的课程也测试了前四章。自那以后，我们在多次提供ECE408课程、Coursera异构并行编程课程以及VSCSE和PUMPS暑期学校时使用了本书。

#### 两阶段方法

本书中的大部分章节设计为每章在约75分钟的讲座中覆盖。需要两个75分钟讲座才能完全覆盖的章节包括第11章（前缀和（扫描））、第14章（稀疏矩阵计算）和第15章（图遍历）。在ECE408课程中，讲座、编程作业和期末项目是同步进行的，并分为两个阶段。

在第一阶段（本书的第一部分和第二部分），学生学习基本概念和基本模式，并通过指导性的编程作业练习所学技能。此阶段包括12章，通常需要约七周时间。每周，学生完成与当周讲座对应的编程作业。例如，在第一周，基于第2章的讲座致力于教授基本的CUDA内存/线程模型、C语言的CUDA扩展和基本的编程工具。在该讲座之后，学生可以在几小时内编写一个简单的向量加法代码。

接下来的两周包括基于第3到第6章的一系列四个讲座，学生将了解CUDA内存模型、CUDA线程执行模型、GPU硬件性能特性和现代计算机系统架构。在这两周内，学生将进行矩阵乘法的不同实现，并在此过程中看到其实现性能显著提高。在剩下的四周，讲座涵盖基于第7到第12章的常见数据并行编程模式，学生完成卷积、直方图、归约和前缀和的作业。在第一阶段结束时，学生应该对并行编程非常熟悉，并准备好在更少指导下实现更高级的代码。

在第二阶段（本书的第三部分和第四部分），学生学习高级模式和应用，同时进行期末项目，该项目涉及加速高级模式或应用。学生还学习在完成项目时可能有用的高级实践。虽然我们通常在此阶段不安排每周的编程作业，但项目通常有每周的里程碑以帮助学生自我节奏。根据课程的时长和格式，讲师可能无法覆盖此阶段的所有章节，需要跳过一些章节。讲师还可以选择用嘉宾讲座、论文讨论会或支持期末项目的讲座替换某些讲座。图P.1中的箭头指示了章节之间的依赖关系，以帮助讲师选择可以跳过或重新排序的章节，以根据他们的特定上下文自定义课程。

#### 汇总：期末项目

虽然讲座、实验和本书的章节帮助学生奠定了知识基础，但将学习体验整合在一起的是期末项目。期末项目在整个学期课程中占据了重要位置，需要近两个月的时间。它包括五个创新方面：导师指导、工作坊、诊所、最终报告和研讨会。尽管关于期末项目的许多信息可以在伊利诺伊-NVIDIA GPU教学工具包中找到，但我们想提供这些方面设计背后的理由。

鼓励学生基于代表研究界当前挑战的问题来进行期末项目。为此，讲师应招募若干计算科学研究团队提出问题并担任导师。导师需要提供一到两页的项目规范说明，简要描述应用的意义、导师希望与学生团队在应用上完成的内容、理解和处理应用所需的技术技能（特定类型的数学、物理和化学课程），以及学生可以参考的技术背景、一般信息和构建模块的资源列表，以及具体的URL或FTP路径。这些项目规范说明还为学生提供了在未来职业生涯中定义自己研究项目的学习经验。若干示例可以在伊利诺伊-NVIDIA GPU教学工具包中找到。

#### 设计文档

学生确定项目并组建团队后，需要提交项目设计文档。这有助于他们在开始项目之前思考项目步骤。这种计划能力对他们未来的职业成功至关重要。设计文档应讨论项目的背景和动机、应用级目标和潜在影响、最终应用的主要特性、设计概述、实施计划、性能目标、验证计划和接受测试，以及项目时间表。

#### 项目报告和研讨会

学生需要提交项目报告，阐述团队的关键发现。我们还建议举办全天的班级研讨会。在研讨会上，学生按照团队规模分配的演示时段进行演示。演示期间，学生重点介绍项目报告中最精彩的部分，以惠及整个班级。演示占学生成绩的重要部分。每个学生必须回答个别针对他们的问题，因此同一团队中的个别成员可能获得不同的成绩。研讨会是学生学习制作简明演示的机会，以激励同学阅读完整的论文。

#### 班级竞赛

在2016年，ECE408的注册人数远远超过了期末项目过程所能容纳的水平。因此，我们从期末项目转向了班级竞赛。在学期中，我们宣布竞赛挑战问题。我们用一节课来解释竞赛挑战问题和用于排名团队的规则。所有学生提交的作品都通过自动评分和排名。每个团队的最终排名由执行时间、正确性和并行代码的清晰度决定。学生在学期末展示他们的解决方案并提交最终报告。这一折中方案在班级规模使期末项目不可行时保留了一些期末项目的好处。

#### 课程资源

伊利诺伊-NVIDIA GPU教学工具包是一个公开可用的资源，包含讲义和录音、实验作业、期末项目指南和供使用本书的讲师参考的示例项目规范。此外，我们正在将基于本书的伊利诺伊本科和研究生课程公开提供。虽然本书为这些课程提供了知识内容，但额外的材料对于实现整体教育目标至关重要。

最后，我们鼓励您提交反馈。如果您有任何改进本书的想法，我们希望听到您的意见。我们希望了解如何改进在线补充材料。当然，我们也希望知道您喜欢本书的哪些内容。我们期待听到您的意见。

Wen-mei W. Hwu  
David B. Kirk  
Izzat El Hajj


上一章 [前言](https://github.com/tunglinwood/CUDA/blob/main/0_%E5%89%8D%E8%A8%80.md)
下一章 [第一章 介绍并行运算](https://github.com/tunglinwood/CUDA/blob/main/1_%E4%BB%8B%E7%BB%8D%E5%B9%B6%E8%A1%8C%E8%BF%90%E7%AE%97.md)
